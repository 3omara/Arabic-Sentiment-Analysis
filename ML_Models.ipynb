{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKoGGi6kLGOO"
   },
   "source": [
    "# Importing Modules and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('./Scripts')\n",
    "sys.path.append('./Files')\n",
    "sys.path.append('./Datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('pip install nltk')\n",
    "os.system('pip install openpyxl')\n",
    "os.system('pip install emot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "id": "UrjWYyRaH06H",
    "outputId": "6a81f367-faab-46f2-f597-6bd3da2443c6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\youss\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "import openpyxl\n",
    "import emot\n",
    "import pickle\n",
    "\n",
    "# from google.colab import files\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "nltk.download('punkt')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from Sequencer import Sequencer\n",
    "from helper_fns import write_dict\n",
    "from helper_fns import read_dict\n",
    "\n",
    "from dataCleaner import clean_arabic_text\n",
    "\n",
    "import ArStemmerLib as lib\n",
    "import lexicon\n",
    "from lexicon import calc_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "K8NHuxV9Jiqq"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Datasets/merged_train_datasets.csv')\n",
    "df = df.rename(columns={\"text\":\"tweet\"})\n",
    "\n",
    "try:\n",
    "    df.drop(columns=['Unnamed: 0'], inplace = True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_df = pd.read_csv('Datasets/tweets_sns2.csv')\n",
    "# keep_regex = \"[Vv]odafone|VODAFONE|فودافون|[Ee]tisalat|ETISALAT|اتصالات|[Oo]range|ORANGE|اورانج|موبينيل|إتصالات|أورانج\"\n",
    "# remove_regex = \"لون\"\n",
    "# drop_indeces = tweets_df[(tweets_df['text'].str.contains(keep_regex)==False) | (tweets_df['text'].str.contains(remove_regex)==True)].index\n",
    "# tweets_df.drop(drop_indeces, inplace=True)\n",
    "# tweets= tweets_df['text'].copy()\n",
    "# tweets2 = df['tweet'].copy()\n",
    "# tokens1 = set(nltk.word_tokenize(' '.join(tweets.to_numpy().flatten())))\n",
    "# tokens2 = set(nltk.word_tokenize(' '.join(tweets2.to_numpy().flatten())))\n",
    "# def tweet_filter(tweet: str, bucket: set[str]) -> bool:\n",
    "#     tokens = set(nltk.word_tokenize(tweet))\n",
    "#     inclusion_ratio =  len(tokens.intersection(bucket)) / len(tokens)\n",
    "#     return inclusion_ratio >= 0.5\n",
    "\n",
    "# filtered_tweets = tweets.to_numpy()[[tweet_filter(x, tokens2) for x in tweets.to_numpy()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "OAo1GEUejnmw"
   },
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7YUwwakVjsBf",
    "outputId": "617b1a14-e1e2-41d8-e427-f6d486ce65b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5819 entries, 0 to 6636\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   tweet      5819 non-null   object\n",
      " 1   sentiment  5819 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 136.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "LgTZtudCnAYh",
    "outputId": "584ef3a6-cca0-4a84-b764-4cc45ed9ce38"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>أهنئ الدكتور أحمد جمال الدين، القيادي بحزب مصر...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>البرادعي يستقوى بامريكا مرةاخرى و يرسل عصام ال...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>الوالدة لو اقولها بخاطري حشيشة تضحك بس من اقول...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#انتخبوا_العرص #انتخبوا_البرص #مرسى_رئيسى #اين...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>امير عيد هو اللي فعلا يتقال عليه ستريكر صريح #...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet sentiment\n",
       "0  أهنئ الدكتور أحمد جمال الدين، القيادي بحزب مصر...  positive\n",
       "1  البرادعي يستقوى بامريكا مرةاخرى و يرسل عصام ال...  negative\n",
       "2  الوالدة لو اقولها بخاطري حشيشة تضحك بس من اقول...   neutral\n",
       "3  #انتخبوا_العرص #انتخبوا_البرص #مرسى_رئيسى #اين...   neutral\n",
       "4  امير عيد هو اللي فعلا يتقال عليه ستريكر صريح #...  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "dWmCJDvoQWET",
    "outputId": "98f72455-5352-4b51-f998-bc14483e32ac"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUhUlEQVR4nO3de5DmVX3n8fdHQBNFA4SR5ZphybjZMcYBpgAl2cWwy60SUYMEssglbI2pBSsYs1uY2gpEQ5aUt4qXkGCcABsi4oV1pFhxMkoSKREGlwADIrOAC7MII+AtJGbB7/7xOx0fsLtPz9BPX6bfr6qn+vzO73a6f93Pp8/vcp5UFZIkTed5890ASdLCZ1hIkroMC0lSl2EhSeoyLCRJXTvPdwPGYc8996zly5fPdzMkaVG59dZbv1lVyyabt0OGxfLly9m4ceN8N0OSFpUkX59qnqehJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoaW1gk2T/JF5LclWRTkt9s9Rcm2ZLktvY6YWSdtyfZnOSeJMeO1B/X6jYnOX9cbZYkTW6cT3A/Bbytqr6S5MXArUnWt3nvq6p3jy6cZCVwCvByYB/gr5K8rM3+EPDvgYeAW5Ksq6q7xth2LRL/5x2vmO8m7PAO+N075rsJWgDGFhZV9TDwcCt/N8ndwL7TrHIicFVVfR+4P8lm4LA2b3NV3QeQ5Kq2rGEhSXNkTq5ZJFkOHAx8uVWdm+T2JGuT7N7q9gUeHFntoVY3Vf2z97EmycYkG7du3Trb34IkLWljD4skuwKfBM6rqu8AlwAHAasYeh7vmY39VNWlVbW6qlYvWzbpoImSpO001lFnk+zCEBRXVtWnAKrqkZH5HwaubZNbgP1HVt+v1TFNvSRpDozzbqgAHwHurqr3jtTvPbLY64E7W3kdcEqSFyQ5EFgB3AzcAqxIcmCS5zNcBF83rnZLkn7UOHsWRwJvAu5Iclur+x3g1CSrgAIeAN4MUFWbklzNcOH6KeCcqnoaIMm5wPXATsDaqto0xnZLkp5lnHdDfRHIJLOum2adi4CLJqm/brr1JEnj5RPckqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHWNLSyS7J/kC0nuSrIpyW+2+j2SrE9yb/u6e6tPkvcn2Zzk9iSHjGzrjLb8vUnOGFebJUmTG2fP4ingbVW1EjgCOCfJSuB8YENVrQA2tGmA44EV7bUGuASGcAEuAA4HDgMumAgYSdLcGFtYVNXDVfWVVv4ucDewL3AicHlb7HLgda18InBFDW4CdkuyN3AssL6qHq+qJ4D1wHHjarck6UfNyTWLJMuBg4EvA3tV1cNt1jeAvVp5X+DBkdUeanVT1T97H2uSbEyycevWrbP7DUjSEjf2sEiyK/BJ4Lyq+s7ovKoqoGZjP1V1aVWtrqrVy5Ytm41NSpKasYZFkl0YguLKqvpUq36knV6ifX201W8B9h9Zfb9WN1W9JGmOjPNuqAAfAe6uqveOzFoHTNzRdAbw6ZH609tdUUcA326nq64Hjkmye7uwfUyrkyTNkZ3HuO0jgTcBdyS5rdX9DnAxcHWSs4GvAye3edcBJwCbgSeBswCq6vEk7wRuacu9o6oeH2O7JUnPMrawqKovApli9tGTLF/AOVNsay2wdvZaJ0naFj7BLUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqWucAwkuGof+5yvmuwk7vFvfdfp8N0HSc2DPQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6hpbWCRZm+TRJHeO1F2YZEuS29rrhJF5b0+yOck9SY4dqT+u1W1Ocv642itJmto4exaXAcdNUv++qlrVXtcBJFkJnAK8vK3zx0l2SrIT8CHgeGAlcGpbVpI0h3Ye14ar6m+SLJ/h4icCV1XV94H7k2wGDmvzNlfVfQBJrmrL3jXb7ZUkTW1sYTGNc5OcDmwE3lZVTwD7AjeNLPNQqwN48Fn1h0+20SRrgDUABxxwwGy3WdIYHPmBI+e7CTu8G99y46xsZ64vcF8CHASsAh4G3jNbG66qS6tqdVWtXrZs2WxtVpLEHPcsquqRiXKSDwPXtsktwP4ji+7X6pimXpI0R2bUs0iyYSZ1M9jO3iOTrwcm7pRaB5yS5AVJDgRWADcDtwArkhyY5PkMF8HXbet+JUnPzbQ9iyQ/BrwQ2DPJ7kDarJfww2sKU637UeCotu5DwAXAUUlWAQU8ALwZoKo2Jbma4cL1U8A5VfV02865wPXATsDaqtq0zd+lJOk56Z2GejNwHrAPcCs/DIvvAB+cbsWqOnWS6o9Ms/xFwEWT1F8HXNdppyRpjKYNi6r6I+CPkrylqj4wR22SJC0wM7rAXVUfSPJqYPnoOlV1xZjaJUlaQGYUFkn+O8Mtr7cBT7fqAgwLSVoCZnrr7GpgZVXVOBsjSVqYZvpQ3p3AvxhnQyRJC9dMexZ7AncluRn4/kRlVb12LK2SJC0oMw2LC8fZCEnSwjbTu6H+etwNkSQtXDO9G+q7DHc/ATwf2AX4+6p6ybgaJklaOGbas3jxRDlJGD5T4ohxNUqStLBs8xDlNfgfwLG9ZSVJO4aZnoZ6w8jk8xieu/jHsbRIkrTgzPRuqF8eKT/FMGLsibPeGknSgjTTaxZnjbshkqSFa6YffrRfkmuSPNpen0yy37gbJ0laGGZ6gfvPGT6hbp/2+kyrkyQtATMNi2VV9edV9VR7XQYsG2O7JEkLyEzD4rEkpyXZqb1OAx4bZ8MkSQvHTMPi14GTgW8ADwMnAWeOqU2SpAVmprfOvgM4o6qeAEiyB/BuhhCRJO3gZtqz+LmJoACoqseBg8fTJEnSQjPTsHhekt0nJlrPYqa9EknSIjfTN/z3AF9K8vE2/UbgovE0SZK00Mz0Ce4rkmwEfrFVvaGq7hpfsyRJC8mMTyW1cDAgJGkJ2uYhyiVJS49hIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktQ1trBIsrZ9qt6dI3V7JFmf5N72dfdWnyTvT7I5ye1JDhlZ54y2/L1JzhhXeyVJUxtnz+Iy4Lhn1Z0PbKiqFcCGNg1wPLCivdYAl8A/j0F1AXA4cBhwwegYVZKkuTG2sKiqvwEef1b1icDlrXw58LqR+itqcBOwW5K9gWOB9VX1eBv1dj0/GkCSpDGb62sWe1XVw638DWCvVt4XeHBkuYda3VT1PyLJmiQbk2zcunXr7LZakpa4ebvAXVUF1Cxu79KqWl1Vq5ct8+PBJWk2zXVYPNJOL9G+PtrqtwD7jyy3X6ubql6SNIfmOizWARN3NJ0BfHqk/vR2V9QRwLfb6arrgWOS7N4ubB/T6iRJc2hsn3aX5KPAUcCeSR5iuKvpYuDqJGcDXwdObotfB5wAbAaeBM6C4eNbk7wTuKUt9472ka6SpDk0trCoqlOnmHX0JMsWcM4U21kLrJ3FpkmStpFPcEuSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUNS9hkeSBJHckuS3Jxla3R5L1Se5tX3dv9Uny/iSbk9ye5JD5aLMkLWXz2bN4TVWtqqrVbfp8YENVrQA2tGmA44EV7bUGuGTOWypJS9xCOg11InB5K18OvG6k/ooa3ATslmTveWifJC1Z8xUWBXwuya1J1rS6varq4Vb+BrBXK+8LPDiy7kOt7hmSrEmyMcnGrVu3jqvdkrQk7TxP+/35qtqS5KXA+iRfHZ1ZVZWktmWDVXUpcCnA6tWrt2ldSdL05qVnUVVb2tdHgWuAw4BHJk4vta+PtsW3APuPrL5fq5MkzZE5D4skL0ry4okycAxwJ7AOOKMtdgbw6VZeB5ze7oo6Avj2yOkqSdIcmI/TUHsB1ySZ2P9fVtVnk9wCXJ3kbODrwMlt+euAE4DNwJPAWXPfZEla2uY8LKrqPuCVk9Q/Bhw9SX0B58xB0yRJU1hIt85KkhYow0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUtmrBIclySe5JsTnL+fLdHkpaSRREWSXYCPgQcD6wETk2ycn5bJUlLx6IIC+AwYHNV3VdV/wRcBZw4z22SpCUjVTXfbehKchJwXFX9xzb9JuDwqjp3ZJk1wJo2+a+Ae+a8oXNnT+Cb890IbTeP3+K1ox+7n6qqZZPN2HmuWzIuVXUpcOl8t2MuJNlYVavnux3aPh6/xWspH7vFchpqC7D/yPR+rU6SNAcWS1jcAqxIcmCS5wOnAOvmuU2StGQsitNQVfVUknOB64GdgLVVtWmemzWflsTpth2Yx2/xWrLHblFc4JYkza/FchpKkjSPDAtJUpdhscgk+Y0kp7fymUn2GZn3Zz7Zvrgk2S3JfxqZ3ifJJ+azTZpekuVJfm071/3ebLdnrnjNYhFLcgPw21W1cb7bou2TZDlwbVX97Hy3RTOT5CiGv7tfmmTezlX11DTrfq+qdh1j88bGnsUcav+RfDXJlUnuTvKJJC9McnSS/5XkjiRrk7ygLX9xkruS3J7k3a3uwiS/3Z5qXw1cmeS2JD+e5IYkq1vv410j+z0zyQdb+bQkN7d1/rSNu6UptGN2d5IPJ9mU5HPtZ31Qks8muTXJ3yb5mbb8QUluasfy9yf+k0yya5INSb7S5k0MV3MxcFA7Hu9q+7uzrXNTkpePtGXi+L6o/Z7c3H5vHPpmBrbjWF7W/s4m1p/oFVwM/EI7Zm9tf1/rknwe2DDNsV7cqsrXHL2A5UABR7bptcB/BR4EXtbqrgDOA36SYciSid7fbu3rhQz/1QDcAKwe2f4NDAGyjGEsrYn6/wn8PPCvgc8Au7T6PwZOn++fy0J+tWP2FLCqTV8NnAZsAFa0usOBz7fytcCprfwbwPdaeWfgJa28J7AZSNv+nc/a352t/Fbg91p5b+CeVv4D4LSJ3wvga8CL5vtntdBf23EsLwNOGll/4lgexdAbnKg/E3gI2GO6Yz26jcX4smcx9x6sqhtb+S+Ao4H7q+prre5y4N8A3wb+EfhIkjcAT850B1W1FbgvyRFJfhL4GeDGtq9DgVuS3Nam/+Vz/5Z2ePdX1W2tfCvDm86rgY+3n+OfMryZA7wK+Hgr/+XINgL8QZLbgb8C9gX26uz3amDiP9uTgYlrGccA57d93wD8GHDAtn1LS9a2HMttsb6qHm/l7TnWC96ieChvB/Psi0TfYuhFPHOh4UHEwxje0E8CzgV+cRv2cxXDG8xXgWuqqpIEuLyq3r49DV/Cvj9SfprhD/9bVbVqG7bxHxh6fIdW1f9L8gDDm/yUqmpLkseS/Bzwqww9FRjejH6lqnbkwTLHZVuO5VO0U/VJngc8f5rt/v1IeZuP9WJgz2LuHZDkVa38a8BGYHmSn251bwL+OsmuwE9U1XUMpyNeOcm2vgu8eIr9XMMwjPupDMEBQ3f7pCQvBUiyR5Kfeq7f0BL0HeD+JG8EyGDi+NwE/EornzKyzk8Aj7Y3j9cAEz/36Y4hwMeA/8Lwu3B7q7seeEsLf5Ic/Fy/oSVsumP5AENPHOC1wC6t3DtmUx3rRc2wmHv3AOckuRvYHXgfcBZDN/gO4AfAnzD8Ml7burJfBH5rkm1dBvzJxAXu0RlV9QRwN8OQwze3ursYrpF8rm13PdvX5dbw3+PZSf4O2MQPP1/lPOC32s/3pxlOJwJcCaxux/h0hh4fVfUYcGOSO0dvShjxCYbQuXqk7p0Mb1y3J9nUprX9pjqWHwb+bat/FT/sPdwOPJ3k75K8dZLtTXqsFztvnZ1D8TbJHV6SFwL/0E77ncJwsXvHuBtGS5rXLKTZdSjwwXaK6FvAr89vc6TZYc9CktTlNQtJUpdhIUnqMiwkSV2GhTTLkqxKcsLI9GuTnD/mfR6V5NXj3IeWNsNCmn2rgH8Oi6paV1UXj3mfRzEMWyGNhXdDSSOSvIjhAbj9GD7v/Z0MA8G9F9gV+CZwZlU9nGGI+C8Dr2EY0O/sNr0Z+HFgC/DfWnl1VZ2b5DLgH4CDgZcy3Fp7OsNDX1+uqjNbO44Bfg94AfC/gbOq6ntt6IjLgV9meDDvjQxjiN3EMHzFVuAtVfW3Y/jxaAmzZyE903HA/62qV7aHJz8LfIBh9NFDGUYKvmhk+Z2r6jCGJ7cvqKp/An4X+FhVraqqj02yj90ZwuGtwDqGp/hfDryincLak+FJ+39XVYcwDAkz+gT/N1v9JQwjED/A8NT/+9o+DQrNOh/Kk57pDuA9Sf6QYbjxJ4CfBda3oZh2Ah4eWf5T7evECKYz8Zn2hPcdwCNVdQdAG7pjOUOvZiXDMCAwDGD3pSn2+YZt+N6k7WZYSCOq6mtJDmG45vD7wOeBTVX1qilWmRjF9Glm/vc0sc4PeOYoqD9o23iaYcjrU2dxn9Jz4mkoaUSGzzR/sqr+AngXw4fhLJsYKTjJLqOfXjeF3qikPTcBR06MRNw+Ge9lY96nNC3DQnqmVwA3tw/CuYDh+sNJwB+20Udvo3/X0ReAlW004F/d1ga0D686E/hoG732SwwfYDWdzwCvb/v8hW3dp9Tj3VCSpC57FpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqev/AzdbCDzzIbbtAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = sns.countplot(x='sentiment', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_JU9GYlilEAx"
   },
   "source": [
    "# Calling methods for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "GsiNTH3TGyfF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        أهنئ الدكتور أحمد جمال الدين، القيادي بحزب مصر...\n",
       "2        البرادعي يستقوى بامريكا مرةاخرى و يرسل عصام ال...\n",
       "4        الوالدة لو اقولها بخاطري حشيشة تضحك بس من اقول...\n",
       "5        #انتخبوا_العرص #انتخبوا_البرص #مرسى_رئيسى #اين...\n",
       "6        امير عيد هو اللي فعلا يتقال عليه ستريكر صريح #...\n",
       "                               ...                        \n",
       "14283    لا ولاقى واحد بيقول قطر بتمول الوايت نايتس !!!...\n",
       "14284    اقسم بالله شركه اورانج دى عليها كرم وذوق عدى ا...\n",
       "14285    اعلان فودافون عمرو دياب واعلان اورانج  واعلان ...\n",
       "14286                   اعلان فودافون يستاهل يطلع تريند ♥️\n",
       "14287    منزلة ستوري واتساب ع حوار إنك تفتح نت من فوداف...\n",
       "Name: tweet, Length: 7502, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df.tweet.map(lambda tweet : clean_arabic_text(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6mW7GUymhLH"
   },
   "source": [
    "# Vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "vt3_NOLVnn_N"
   },
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2KbRcpe5CDog"
   },
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8EB9aBqUlk_I"
   },
   "source": [
    "# Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Text Preprocessing Experimentations/exp1_train_rtp_rl_re_cat_rl_qalsadi.csv\")\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "08yU2oHFloYJ"
   },
   "outputs": [],
   "source": [
    "X_train_tfidf,X_test_tfidf,Y_train_tfidf,Y_test_tfidf = train_test_split(tfidf_vec.fit_transform(df['tweet']), df['sentiment'], test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "wBDnCyIxCcrm"
   },
   "outputs": [],
   "source": [
    "X_train_count,X_test_count,Y_train_count,Y_test_count = train_test_split(count_vec.fit_transform(df['tweet']), df['sentiment'], test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train ,X_test ,Y_train ,Y_test  = train_test_split(df['tweet'], df['sentiment'], test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6333    positive\n",
       "4891    positive\n",
       "1050     neutral\n",
       "5629     neutral\n",
       "6434     neutral\n",
       "Name: sentiment, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "Y_test_tfidf = le.fit_transform(Y_test_tfidf)\n",
    "Y_test_count = le.fit_transform(Y_test_count)\n",
    "Y_test = le.fit_transform(Y_test)\n",
    "Y_train_tfidf = le.fit_transform(Y_train_tfidf)\n",
    "Y_train_count = le.fit_transform(Y_train_count)\n",
    "Y_train = le.fit_transform(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NkPLDKRLYqJZ"
   },
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Lexicon and Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the lexicon\n",
    "tweet_train_lex = []\n",
    "for tweet in X_train:\n",
    "    tweet_train_lex.append(calc_lexicon(u\"%s\" %tweet))\n",
    "\n",
    "tweet_test_lex = []\n",
    "for tweet in X_test:\n",
    "    tweet_test_lex.append(calc_lexicon(u\"%s\" %tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "CFdraTg7YvU8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1455x2 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1163 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "tweet_lex_train_sparse = csr_matrix(tweet_train_lex)\n",
    "tweet_lex_test_sparse = csr_matrix(tweet_test_lex)\n",
    "tweet_lex_test_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "DQRPxYCmYxQg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1455x16716 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13575 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_matrix = hstack((X_train_count, tweet_lex_train_sparse))\n",
    "test_feature_matrix = hstack((X_test_count, tweet_lex_test_sparse))\n",
    "test_feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "OvrKyk5PZqm8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 59.03780068728523%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.77      0.68       639\n",
      "     neutral       0.41      0.21      0.28       371\n",
      "    positive       0.61      0.66      0.63       445\n",
      "\n",
      "    accuracy                           0.59      1455\n",
      "   macro avg       0.55      0.54      0.53      1455\n",
      "weighted avg       0.56      0.59      0.57      1455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_lexicon = cl.fit(train_feature_matrix,Y_train)\n",
    "predicted = cl.predict(test_feature_matrix)\n",
    "acc = accuracy_score(Y_test,predicted)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_lex_model_path = 'Models/nb_lexicon_model.sav'\n",
    "pickle.dump(nb_lexicon, open(nb_lex_model_path,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNju2dCSnfow"
   },
   "source": [
    "## Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "tovTo0rFoKFr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 56.42611683848797%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.93      0.67       639\n",
      "     neutral       0.48      0.03      0.06       371\n",
      "    positive       0.70      0.49      0.58       445\n",
      "\n",
      "    accuracy                           0.56      1455\n",
      "   macro avg       0.57      0.48      0.44      1455\n",
      "weighted avg       0.57      0.56      0.49      1455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_tfidf = cl.fit(X_train_tfidf, Y_train_tfidf)\n",
    "p = cl.predict(X_test_tfidf)\n",
    "acc = accuracy_score(Y_test_tfidf,p)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_tfidf_model_path = 'Models/nb_tfidf_model.sav'\n",
    "pickle.dump(nb_tfidf, open(nb_tfidf_model_path,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexicon + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1455x16716 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13575 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_matrix_tf = hstack((X_train_tfidf, tweet_lex_train_sparse))\n",
    "test_feature_matrix_tf = hstack((X_test_tfidf, tweet_lex_test_sparse))\n",
    "test_feature_matrix_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 57.66323024054982%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.88      0.68       639\n",
      "     neutral       0.54      0.04      0.08       371\n",
      "    positive       0.63      0.59      0.61       445\n",
      "\n",
      "    accuracy                           0.58      1455\n",
      "   macro avg       0.57      0.50      0.45      1455\n",
      "weighted avg       0.57      0.58      0.50      1455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_lex_tfidf = cl.fit(train_feature_matrix_tf,Y_train)\n",
    "predicted = cl.predict(test_feature_matrix_tf)\n",
    "acc = accuracy_score(Y_test,predicted)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_lex_tfidf_model_path = 'Models/nb_lex_tfidf_model.sav'\n",
    "pickle.dump(nb_lex_tfidf, open(nb_lex_tfidf_model_path,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOswlrtZJK_G"
   },
   "source": [
    "# Logistic Regression TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "4ZDYb8IzJT7S"
   },
   "outputs": [],
   "source": [
    "lg =  LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "EoBqNWdbJWB6"
   },
   "outputs": [],
   "source": [
    "# make param grid\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# create and fit the model\n",
    "model = GridSearchCV(lg, param_grid, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_model_path = 'Models/exp1_lg_tfidf_model.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "Xq49spN8JslI"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train_tfidf,Y_train_tfidf)\n",
    "pickle.dump(model, open(lg_model_path,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "QWb51vfLN3ND"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 0.57\n"
     ]
    }
   ],
   "source": [
    "# make prediction and print accuracy\n",
    "prediction = model.predict(X_test_tfidf)\n",
    "print(f\"Accuracy score is {accuracy_score(Y_test_tfidf, prediction):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "oTZWrjiQN8zg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.54      0.87      0.67       639\n",
      "     neutral       0.44      0.10      0.16       371\n",
      "    positive       0.66      0.52      0.58       445\n",
      "\n",
      "    accuracy                           0.57      1455\n",
      "   macro avg       0.55      0.50      0.47      1455\n",
      "weighted avg       0.55      0.57      0.51      1455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Reg using Lexicon + Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 0.58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.78      0.69       639\n",
      "     neutral       0.42      0.12      0.18       371\n",
      "    positive       0.56      0.68      0.62       445\n",
      "\n",
      "    accuracy                           0.58      1455\n",
      "   macro avg       0.53      0.53      0.49      1455\n",
      "weighted avg       0.55      0.58      0.54      1455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lg_lexicon = model.fit(train_feature_matrix,Y_train)\n",
    "pickle.dump(model, open(lg_model_path,'wb'))\n",
    "prediction = model.predict(test_feature_matrix)\n",
    "print(f\"Accuracy score is {accuracy_score(Y_test, prediction):.2f}\")\n",
    "print(classification_report(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_lexicon_model_path = 'Models/lg_lexicon_model.sav'\n",
    "pickle.dump(lg_lexicon, open(lg_lexicon_model_path,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complement Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"Text Preprocessing Experimentations/exp1_train_rtp_rl_re_cat_rl_qalsadi.csv\"\n",
    "CNB_df = pd.read_csv(data_path)\n",
    "CNB_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNB = ComplementNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnb_tfidf,X_test_cnb_tfidf,Y_train_cnb_tfidf,Y_test_cnb_tfidf = train_test_split(tfidf_vec.fit_transform(CNB_df['tweet']), CNB_df['sentiment'], test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ComplementNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ComplementNB</label><div class=\"sk-toggleable__content\"><pre>ComplementNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ComplementNB()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNB.fit(X_train_cnb_tfidf, Y_train_cnb_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 60.66024759284731%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.73      0.69       682\n",
      "     neutral       0.36      0.21      0.26       362\n",
      "    positive       0.64      0.75      0.69       410\n",
      "\n",
      "    accuracy                           0.61      1454\n",
      "   macro avg       0.55      0.56      0.55      1454\n",
      "weighted avg       0.58      0.61      0.58      1454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = CNB.predict(X_test_cnb_tfidf)\n",
    "acc = accuracy_score(Y_test_cnb_tfidf,predicted)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test_cnb_tfidf,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_SVC = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"Text Preprocessing Experimentations/exp1_train_rtp_rl_rd_re_cat_rl_qalsadi.csv\"\n",
    "embedding_path = \"Word Embeddings/sg_dict_exp1_5_2_100.txt\"\n",
    "padding = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df = pd.read_csv(data_path)\n",
    "preprocessed_df.dropna(inplace=True)\n",
    "\n",
    "embeddings_dict = read_dict(embedding_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequencer = Sequencer(preprocessed_df['tweet'], embeddings_dict, padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_matrix = []\n",
    "for tweet in preprocessed_df['tweet']:\n",
    "    tweet_vec = sequencer.padder(sequencer.text_to_vec(tweet))\n",
    "    embeddings_matrix.append(tweet_vec)\n",
    "embeddings_matrix = np.array(embeddings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.055908</td>\n",
       "      <td>0.160340</td>\n",
       "      <td>0.051328</td>\n",
       "      <td>-0.056218</td>\n",
       "      <td>0.076106</td>\n",
       "      <td>-0.178284</td>\n",
       "      <td>0.092494</td>\n",
       "      <td>0.251977</td>\n",
       "      <td>-0.092725</td>\n",
       "      <td>-0.119950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166078</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.038269</td>\n",
       "      <td>0.011544</td>\n",
       "      <td>0.199726</td>\n",
       "      <td>0.086804</td>\n",
       "      <td>0.038677</td>\n",
       "      <td>-0.130935</td>\n",
       "      <td>0.023692</td>\n",
       "      <td>0.019647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.078046</td>\n",
       "      <td>0.215733</td>\n",
       "      <td>0.057535</td>\n",
       "      <td>-0.079298</td>\n",
       "      <td>0.096619</td>\n",
       "      <td>-0.228640</td>\n",
       "      <td>0.141090</td>\n",
       "      <td>0.347706</td>\n",
       "      <td>-0.136595</td>\n",
       "      <td>-0.163156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.070160</td>\n",
       "      <td>0.179415</td>\n",
       "      <td>0.048638</td>\n",
       "      <td>-0.051211</td>\n",
       "      <td>0.076645</td>\n",
       "      <td>-0.184004</td>\n",
       "      <td>0.108458</td>\n",
       "      <td>0.267200</td>\n",
       "      <td>-0.114240</td>\n",
       "      <td>-0.126969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262378</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.065481</td>\n",
       "      <td>0.015891</td>\n",
       "      <td>0.326735</td>\n",
       "      <td>0.138497</td>\n",
       "      <td>0.078392</td>\n",
       "      <td>-0.205730</td>\n",
       "      <td>0.054721</td>\n",
       "      <td>0.033988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.085619</td>\n",
       "      <td>0.237325</td>\n",
       "      <td>0.052841</td>\n",
       "      <td>-0.067491</td>\n",
       "      <td>0.108453</td>\n",
       "      <td>-0.243092</td>\n",
       "      <td>0.129196</td>\n",
       "      <td>0.376145</td>\n",
       "      <td>-0.162666</td>\n",
       "      <td>-0.164792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.079131</td>\n",
       "      <td>0.237908</td>\n",
       "      <td>0.064046</td>\n",
       "      <td>-0.072542</td>\n",
       "      <td>0.112795</td>\n",
       "      <td>-0.246188</td>\n",
       "      <td>0.151964</td>\n",
       "      <td>0.381865</td>\n",
       "      <td>-0.142641</td>\n",
       "      <td>-0.170898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.055908  0.160340  0.051328 -0.056218  0.076106 -0.178284  0.092494   \n",
       "1 -0.078046  0.215733  0.057535 -0.079298  0.096619 -0.228640  0.141090   \n",
       "2 -0.070160  0.179415  0.048638 -0.051211  0.076645 -0.184004  0.108458   \n",
       "3 -0.085619  0.237325  0.052841 -0.067491  0.108453 -0.243092  0.129196   \n",
       "4 -0.079131  0.237908  0.064046 -0.072542  0.112795 -0.246188  0.151964   \n",
       "\n",
       "        7         8         9    ...       990       991       992       993  \\\n",
       "0  0.251977 -0.092725 -0.119950  ...  0.166078  0.008811  0.038269  0.011544   \n",
       "1  0.347706 -0.136595 -0.163156  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.267200 -0.114240 -0.126969  ...  0.262378  0.007275  0.065481  0.015891   \n",
       "3  0.376145 -0.162666 -0.164792  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.381865 -0.142641 -0.170898  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        994       995       996       997       998       999  \n",
       "0  0.199726  0.086804  0.038677 -0.130935  0.023692  0.019647  \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2  0.326735  0.138497  0.078392 -0.205730  0.054721  0.033988  \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embedding = pd.DataFrame(embeddings_matrix)\n",
    "df_embedding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.768772</td>\n",
       "      <td>-1.206973</td>\n",
       "      <td>-0.586278</td>\n",
       "      <td>0.660886</td>\n",
       "      <td>-1.174449</td>\n",
       "      <td>1.107128</td>\n",
       "      <td>-1.392229</td>\n",
       "      <td>-1.353726</td>\n",
       "      <td>1.526361</td>\n",
       "      <td>0.999171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315369</td>\n",
       "      <td>0.206000</td>\n",
       "      <td>0.108101</td>\n",
       "      <td>0.126585</td>\n",
       "      <td>0.288704</td>\n",
       "      <td>0.385811</td>\n",
       "      <td>0.111782</td>\n",
       "      <td>-0.332926</td>\n",
       "      <td>0.174809</td>\n",
       "      <td>0.562743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.166843</td>\n",
       "      <td>0.062077</td>\n",
       "      <td>-0.244797</td>\n",
       "      <td>-0.621521</td>\n",
       "      <td>-0.300307</td>\n",
       "      <td>0.110140</td>\n",
       "      <td>0.152559</td>\n",
       "      <td>-0.021083</td>\n",
       "      <td>0.075464</td>\n",
       "      <td>-0.285877</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.969364</td>\n",
       "      <td>-0.382304</td>\n",
       "      <td>-0.821999</td>\n",
       "      <td>-0.505598</td>\n",
       "      <td>-0.970799</td>\n",
       "      <td>-0.950879</td>\n",
       "      <td>-0.685049</td>\n",
       "      <td>0.967590</td>\n",
       "      <td>-0.776028</td>\n",
       "      <td>-0.347794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.166448</td>\n",
       "      <td>-0.769946</td>\n",
       "      <td>-0.734251</td>\n",
       "      <td>0.939082</td>\n",
       "      <td>-1.151463</td>\n",
       "      <td>0.993863</td>\n",
       "      <td>-0.884745</td>\n",
       "      <td>-1.141805</td>\n",
       "      <td>0.814807</td>\n",
       "      <td>0.790416</td>\n",
       "      <td>...</td>\n",
       "      <td>1.060321</td>\n",
       "      <td>0.103453</td>\n",
       "      <td>0.769472</td>\n",
       "      <td>0.364613</td>\n",
       "      <td>1.089645</td>\n",
       "      <td>1.181816</td>\n",
       "      <td>0.930003</td>\n",
       "      <td>-1.075836</td>\n",
       "      <td>1.420108</td>\n",
       "      <td>1.227371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.486882</td>\n",
       "      <td>0.556756</td>\n",
       "      <td>-0.503029</td>\n",
       "      <td>0.034488</td>\n",
       "      <td>0.203996</td>\n",
       "      <td>-0.175988</td>\n",
       "      <td>-0.225523</td>\n",
       "      <td>0.374829</td>\n",
       "      <td>-0.786788</td>\n",
       "      <td>-0.334540</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.969364</td>\n",
       "      <td>-0.382304</td>\n",
       "      <td>-0.821999</td>\n",
       "      <td>-0.505598</td>\n",
       "      <td>-0.970799</td>\n",
       "      <td>-0.950879</td>\n",
       "      <td>-0.685049</td>\n",
       "      <td>0.967590</td>\n",
       "      <td>-0.776028</td>\n",
       "      <td>-0.347794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.212686</td>\n",
       "      <td>0.570117</td>\n",
       "      <td>0.113394</td>\n",
       "      <td>-0.246136</td>\n",
       "      <td>0.389036</td>\n",
       "      <td>-0.237276</td>\n",
       "      <td>0.498252</td>\n",
       "      <td>0.454446</td>\n",
       "      <td>-0.124496</td>\n",
       "      <td>-0.516155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.969364</td>\n",
       "      <td>-0.382304</td>\n",
       "      <td>-0.821999</td>\n",
       "      <td>-0.505598</td>\n",
       "      <td>-0.970799</td>\n",
       "      <td>-0.950879</td>\n",
       "      <td>-0.685049</td>\n",
       "      <td>0.967590</td>\n",
       "      <td>-0.776028</td>\n",
       "      <td>-0.347794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.768772 -1.206973 -0.586278  0.660886 -1.174449  1.107128 -1.392229   \n",
       "1 -0.166843  0.062077 -0.244797 -0.621521 -0.300307  0.110140  0.152559   \n",
       "2  0.166448 -0.769946 -0.734251  0.939082 -1.151463  0.993863 -0.884745   \n",
       "3 -0.486882  0.556756 -0.503029  0.034488  0.203996 -0.175988 -0.225523   \n",
       "4 -0.212686  0.570117  0.113394 -0.246136  0.389036 -0.237276  0.498252   \n",
       "\n",
       "        7         8         9    ...       990       991       992       993  \\\n",
       "0 -1.353726  1.526361  0.999171  ...  0.315369  0.206000  0.108101  0.126585   \n",
       "1 -0.021083  0.075464 -0.285877  ... -0.969364 -0.382304 -0.821999 -0.505598   \n",
       "2 -1.141805  0.814807  0.790416  ...  1.060321  0.103453  0.769472  0.364613   \n",
       "3  0.374829 -0.786788 -0.334540  ... -0.969364 -0.382304 -0.821999 -0.505598   \n",
       "4  0.454446 -0.124496 -0.516155  ... -0.969364 -0.382304 -0.821999 -0.505598   \n",
       "\n",
       "        994       995       996       997       998       999  \n",
       "0  0.288704  0.385811  0.111782 -0.332926  0.174809  0.562743  \n",
       "1 -0.970799 -0.950879 -0.685049  0.967590 -0.776028 -0.347794  \n",
       "2  1.089645  1.181816  0.930003 -1.075836  1.420108  1.227371  \n",
       "3 -0.970799 -0.950879 -0.685049  0.967590 -0.776028 -0.347794  \n",
       "4 -0.970799 -0.950879 -0.685049  0.967590 -0.776028 -0.347794  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(padding):\n",
    "    df_embedding[i] =( df_embedding[i] - df_embedding[i].mean() ) / df_embedding[i].std()\n",
    "    # df_embedding[str(i)] = [sequencer.padder(sequencer.text_to_vec(tweet))[i] for tweet in df['tweet']]\n",
    "    \n",
    "df_embedding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_em ,X_test_em ,Y_train_em ,Y_test_em  = train_test_split(df_embedding, preprocessed_df['sentiment'], test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 49.10591471801926%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.83      0.61       634\n",
      "     neutral       0.29      0.01      0.01       373\n",
      "    positive       0.53      0.42      0.47       447\n",
      "\n",
      "    accuracy                           0.49      1454\n",
      "   macro avg       0.43      0.42      0.36      1454\n",
      "weighted avg       0.45      0.49      0.41      1454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_embedding = SVM_SVC.fit(X_train_em,Y_train_em)\n",
    "predicted = svc_embedding.predict(X_test_em)\n",
    "acc = accuracy_score(Y_test_em,predicted)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test_em,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf,X_test_tfidf,Y_train_tfidf,Y_test_tfidf = train_test_split(tfidf_vec.fit_transform(preprocessed_df['tweet']), preprocessed_df['sentiment'], test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 59.21595598349381%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.55      0.94      0.69       634\n",
      "     neutral       0.43      0.03      0.06       373\n",
      "    positive       0.76      0.56      0.64       447\n",
      "\n",
      "    accuracy                           0.59      1454\n",
      "   macro avg       0.58      0.51      0.47      1454\n",
      "weighted avg       0.58      0.59      0.52      1454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_tfidf = SVM_SVC.fit(X_train_tfidf,Y_train_tfidf)\n",
    "predicted = svc_tfidf.predict(X_test_tfidf)\n",
    "acc = accuracy_score(Y_test_tfidf,predicted)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test_tfidf,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_count,X_test_count,Y_train_count,Y_test_count = train_test_split(count_vec.fit_transform(preprocessed_df['tweet']), preprocessed_df['sentiment'], test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 57.35900962861072%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.93      0.68       634\n",
      "     neutral       0.38      0.02      0.03       373\n",
      "    positive       0.71      0.54      0.61       447\n",
      "\n",
      "    accuracy                           0.57      1454\n",
      "   macro avg       0.54      0.49      0.44      1454\n",
      "weighted avg       0.55      0.57      0.49      1454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_count = SVM_SVC.fit(X_train_count,Y_train_count)\n",
    "predicted = svc_count.predict(X_test_count)\n",
    "acc = accuracy_score(Y_test_count,predicted)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test_count,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tweets SA task.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
