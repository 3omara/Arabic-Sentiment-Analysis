{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKoGGi6kLGOO"
   },
   "source": [
    "# Importing Modules and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('./Scripts')\n",
    "sys.path.append('./Files')\n",
    "sys.path.append('./Datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('pip install nltk')\n",
    "os.system('pip install openpyxl')\n",
    "os.system('pip install emot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "id": "UrjWYyRaH06H",
    "outputId": "6a81f367-faab-46f2-f597-6bd3da2443c6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\youss\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "import openpyxl\n",
    "import emot\n",
    "import pickle\n",
    "\n",
    "# from google.colab import files\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "nltk.download('punkt')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from dataCleaner import preProcess\n",
    "import ArStemmerLib as lib\n",
    "import lexicon\n",
    "from lexicon import calc_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "K8NHuxV9Jiqq"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('Datasets/tweets_train.csv')\n",
    "df1 = pd.read_csv('Datasets/NU_EG_Twitter_corpus_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>271</td>\n",
       "      <td>negative</td>\n",
       "      <td>فينو الاهبل ابن الاهبل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>131</td>\n",
       "      <td>positive</td>\n",
       "      <td>على المصرييييين وجمالهم ربنا يحميهم #MinaAtta ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118</td>\n",
       "      <td>positive</td>\n",
       "      <td>@Kholoudkewan  دول كتير اوى ودمهم خفيف العمارة...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>negative</td>\n",
       "      <td>انا بعد كده  خلى اللى يوعنى   بحاجه همضى على و...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3430</td>\n",
       "      <td>negative</td>\n",
       "      <td>انا هنتحر</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id sentiment                                              tweet\n",
       "0   271  negative                             فينو الاهبل ابن الاهبل\n",
       "1   131  positive  على المصرييييين وجمالهم ربنا يحميهم #MinaAtta ...\n",
       "2   118  positive  @Kholoudkewan  دول كتير اوى ودمهم خفيف العمارة...\n",
       "3     6  negative  انا بعد كده  خلى اللى يوعنى   بحاجه همضى على و...\n",
       "4  3430  negative                                          انا هنتحر"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Jev7UF4nhv_D"
   },
   "outputs": [],
   "source": [
    "df2.rename(columns={\"text\":\"tweet\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "jfnfj8cGfZvg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\youss\\AppData\\Local\\Temp\\ipykernel_29400\\2019465929.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df2.append(df1,ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "#Appending the data of the two datasets into one data frame\n",
    "df = df2.append(df1,ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['sentiment']=='OBJ'].index, inplace = True)\n",
    "df.drop(df[df['sentiment']=='OBJ\"'].index, inplace = True)\n",
    "\n",
    "df['sentiment'] = df['sentiment'].replace(['NEG\"'],'negative')\n",
    "df['sentiment'] = df['sentiment'].replace(['POS\"'],'positive')\n",
    "df['sentiment'] = df['sentiment'].replace(['NEG'],'negative')\n",
    "df['sentiment'] = df['sentiment'].replace(['POS'],'positive')\n",
    "df['sentiment'] = df['sentiment'].replace(['NEUTRAL'],'neutral')\n",
    "\n",
    "df.drop(\"id\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Datasets/merged_train_datasets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv('Datasets/tweets_sns2.csv')\n",
    "keep_regex = \"[Vv]odafone|VODAFONE|فودافون|[Ee]tisalat|ETISALAT|اتصالات|[Oo]range|ORANGE|اورانج|موبينيل|إتصالات|أورانج\"\n",
    "remove_regex = \"لون\"\n",
    "drop_indeces = tweets_df[(tweets_df['text'].str.contains(keep_regex)==False) | (tweets_df['text'].str.contains(remove_regex)==True)].index\n",
    "tweets_df.drop(drop_indeces, inplace=True)\n",
    "tweets= tweets_df['text'].copy()\n",
    "tweets2 = df['tweet'].copy()\n",
    "tokens1 = set(nltk.word_tokenize(' '.join(tweets.to_numpy().flatten())))\n",
    "tokens2 = set(nltk.word_tokenize(' '.join(tweets2.to_numpy().flatten())))\n",
    "def tweet_filter(tweet: str, bucket: set[str]) -> bool:\n",
    "    tokens = set(nltk.word_tokenize(tweet))\n",
    "    inclusion_ratio =  len(tokens.intersection(bucket)) / len(tokens)\n",
    "    return inclusion_ratio >= 0.5\n",
    "\n",
    "filtered_tweets = tweets.to_numpy()[[tweet_filter(x, tokens2) for x in tweets.to_numpy()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1683"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame()\n",
    "df4['id'] = np.zeros(len(filtered_tweets))\n",
    "df4['sentiment'] = \"positive\"\n",
    "df4['tweet']=filtered_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>0.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>لا ولاقى واحد بيقول قطر بتمول الوايت نايتس !!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>0.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>اقسم بالله شركه اورانج دى عليها كرم وذوق عدى ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>0.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>اعلان فودافون عمرو دياب واعلان اورانج  واعلان ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>0.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>اعلان فودافون يستاهل يطلع تريند ♥️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>0.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>منزلة ستوري واتساب ع حوار إنك تفتح نت من فوداف...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id sentiment                                              tweet\n",
       "1678  0.0  positive  لا ولاقى واحد بيقول قطر بتمول الوايت نايتس !!!...\n",
       "1679  0.0  positive  اقسم بالله شركه اورانج دى عليها كرم وذوق عدى ا...\n",
       "1680  0.0  positive  اعلان فودافون عمرو دياب واعلان اورانج  واعلان ...\n",
       "1681  0.0  positive                 اعلان فودافون يستاهل يطلع تريند ♥️\n",
       "1682  0.0  positive  منزلة ستوري واتساب ع حوار إنك تفتح نت من فوداف..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\youss\\AppData\\Local\\Temp\\ipykernel_11048\\1590877209.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(df4, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df = df.append(df4, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kbkbV9BIhOdw",
    "outputId": "5bd11a35-02d3-4169-e4c3-e71f0806cb59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14288 entries, 0 to 14287\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   tweet      14288 non-null  object \n",
      " 1   sentiment  13470 non-null  object \n",
      " 2   id         4429 non-null   float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 335.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vlj37wFGiLOO",
    "outputId": "0636b169-7840-417f-bb81-23be122a896a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8320 entries, 1 to 14287\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   tweet      8320 non-null   object\n",
      " 1   sentiment  7502 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 195.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "OAo1GEUejnmw"
   },
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7YUwwakVjsBf",
    "outputId": "617b1a14-e1e2-41d8-e427-f6d486ce65b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7502 entries, 1 to 14287\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   tweet      7502 non-null   object\n",
      " 1   sentiment  7502 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 175.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "LgTZtudCnAYh",
    "outputId": "584ef3a6-cca0-4a84-b764-4cc45ed9ce38"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>أهنئ الدكتور أحمد جمال الدين، القيادي بحزب مصر...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>البرادعي يستقوى بامريكا مرةاخرى و يرسل عصام ال...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>الوالدة لو اقولها بخاطري حشيشة تضحك بس من اقول...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#انتخبوا_العرص #انتخبوا_البرص #مرسى_رئيسى #اين...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>امير عيد هو اللي فعلا يتقال عليه ستريكر صريح #...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet sentiment\n",
       "1  أهنئ الدكتور أحمد جمال الدين، القيادي بحزب مصر...  positive\n",
       "2  البرادعي يستقوى بامريكا مرةاخرى و يرسل عصام ال...  negative\n",
       "4  الوالدة لو اقولها بخاطري حشيشة تضحك بس من اقول...   neutral\n",
       "5  #انتخبوا_العرص #انتخبوا_البرص #مرسى_رئيسى #اين...   neutral\n",
       "6  امير عيد هو اللي فعلا يتقال عليه ستريكر صريح #...  positive"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "dWmCJDvoQWET",
    "outputId": "98f72455-5352-4b51-f998-bc14483e32ac"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = sns.countplot(x='sentiment', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_JU9GYlilEAx"
   },
   "source": [
    "# Calling methods for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "GsiNTH3TGyfF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        أهنئ الدكتور أحمد جمال الدين، القيادي بحزب مصر...\n",
       "2        البرادعي يستقوى بامريكا مرةاخرى و يرسل عصام ال...\n",
       "4        الوالدة لو اقولها بخاطري حشيشة تضحك بس من اقول...\n",
       "5        #انتخبوا_العرص #انتخبوا_البرص #مرسى_رئيسى #اين...\n",
       "6        امير عيد هو اللي فعلا يتقال عليه ستريكر صريح #...\n",
       "                               ...                        \n",
       "14283    لا ولاقى واحد بيقول قطر بتمول الوايت نايتس !!!...\n",
       "14284    اقسم بالله شركه اورانج دى عليها كرم وذوق عدى ا...\n",
       "14285    اعلان فودافون عمرو دياب واعلان اورانج  واعلان ...\n",
       "14286                   اعلان فودافون يستاهل يطلع تريند ♥️\n",
       "14287    منزلة ستوري واتساب ع حوار إنك تفتح نت من فوداف...\n",
       "Name: tweet, Length: 7502, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "oXPI8tHDk5Jl"
   },
   "outputs": [],
   "source": [
    "preProcess(df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6mW7GUymhLH"
   },
   "source": [
    "# Vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "vt3_NOLVnn_N"
   },
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "2KbRcpe5CDog"
   },
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8EB9aBqUlk_I"
   },
   "source": [
    "# Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "08yU2oHFloYJ"
   },
   "outputs": [],
   "source": [
    "X_train_tfidf,X_test_tfidf,Y_train_tfidf,Y_test_tfidf = train_test_split(tfidf_vec.fit_transform(df['tweet']), df['sentiment'], test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "wBDnCyIxCcrm"
   },
   "outputs": [],
   "source": [
    "X_train_count,X_test_count,Y_train_count,Y_test_count = train_test_split(count_vec.fit_transform(df['tweet']), df['sentiment'], test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train ,X_test ,Y_train ,Y_test  = train_test_split(df['tweet'], df['sentiment'], test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10140    positive\n",
       "10364    negative\n",
       "2016     negative\n",
       "623      negative\n",
       "9780     positive\n",
       "Name: sentiment, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "Y_test_tfidf = le.fit_transform(Y_test_tfidf)\n",
    "Y_test_count = le.fit_transform(Y_test_count)\n",
    "Y_test = le.fit_transform(Y_test)\n",
    "Y_train_tfidf = le.fit_transform(Y_train_tfidf)\n",
    "Y_train_count = le.fit_transform(Y_train_count)\n",
    "Y_train = le.fit_transform(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NkPLDKRLYqJZ"
   },
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Lexicon and Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the lexicon\n",
    "tweet_train_lex = []\n",
    "for tweet in X_train:\n",
    "    tweet_train_lex.append(calc_lexicon(u\"%s\" %tweet))\n",
    "\n",
    "tweet_test_lex = []\n",
    "for tweet in X_test:\n",
    "    tweet_test_lex.append(calc_lexicon(u\"%s\" %tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "CFdraTg7YvU8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1876x2 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1378 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "tweet_lex_train_sparse = csr_matrix(tweet_train_lex)\n",
    "tweet_lex_test_sparse = csr_matrix(tweet_test_lex)\n",
    "tweet_lex_test_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "DQRPxYCmYxQg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1876x21018 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 18633 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_matrix = hstack((X_train_count, tweet_lex_train_sparse))\n",
    "test_feature_matrix = hstack((X_test_count, tweet_lex_test_sparse))\n",
    "test_feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "OvrKyk5PZqm8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 64.87206823027718%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64       620\n",
      "           1       0.37      0.22      0.27       377\n",
      "           2       0.72      0.83      0.77       879\n",
      "\n",
      "    accuracy                           0.65      1876\n",
      "   macro avg       0.57      0.57      0.56      1876\n",
      "weighted avg       0.62      0.65      0.63      1876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_lexicon = cl.fit(train_feature_matrix,Y_train)\n",
    "predicted = cl.predict(test_feature_matrix)\n",
    "acc = accuracy_score(Y_test,predicted)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_lex_model_path = 'Models/nb_lexicon_model.sav'\n",
    "pickle.dump(nb_lexicon, open(nb_lex_model_path,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNju2dCSnfow"
   },
   "source": [
    "## Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "tovTo0rFoKFr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 62.20682302771855%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.53      0.59       620\n",
      "           1       0.33      0.01      0.02       377\n",
      "           2       0.61      0.95      0.74       879\n",
      "\n",
      "    accuracy                           0.62      1876\n",
      "   macro avg       0.53      0.50      0.45      1876\n",
      "weighted avg       0.57      0.62      0.55      1876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_tfidf = cl.fit(X_train_tfidf, Y_train_tfidf)\n",
    "p = cl.predict(X_test_tfidf)\n",
    "acc = accuracy_score(Y_test_tfidf,p)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_tfidf_model_path = 'Models/nb_tfidf_model.sav'\n",
    "pickle.dump(nb_tfidf, open(nb_tfidf_model_path,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexicon + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1876x21018 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 18633 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_matrix_tf = hstack((X_train_tfidf, tweet_lex_train_sparse))\n",
    "test_feature_matrix_tf = hstack((X_test_tfidf, tweet_lex_test_sparse))\n",
    "test_feature_matrix_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 62.79317697228145%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.60      0.61       620\n",
      "           1       0.20      0.01      0.01       377\n",
      "           2       0.63      0.91      0.75       879\n",
      "\n",
      "    accuracy                           0.63      1876\n",
      "   macro avg       0.49      0.51      0.46      1876\n",
      "weighted avg       0.54      0.63      0.55      1876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_lex_tfidf = cl.fit(train_feature_matrix_tf,Y_train)\n",
    "predicted = cl.predict(test_feature_matrix_tf)\n",
    "acc = accuracy_score(Y_test,predicted)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_lex_tfidf_model_path = 'Models/nb_lex_tfidf_model.sav'\n",
    "pickle.dump(nb_lex_tfidf, open(nb_lex_tfidf_model_path,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOswlrtZJK_G"
   },
   "source": [
    "# Logistic Regression TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "4ZDYb8IzJT7S"
   },
   "outputs": [],
   "source": [
    "lg =  LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "EoBqNWdbJWB6"
   },
   "outputs": [],
   "source": [
    "# make param grid\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# create and fit the model\n",
    "model = GridSearchCV(lg, param_grid, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_model_path = 'Models/lg_tfidf_model.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "Xq49spN8JslI"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train_tfidf,Y_train_tfidf)\n",
    "pickle.dump(model, open(lg_model_path,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "QWb51vfLN3ND"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 0.67\n"
     ]
    }
   ],
   "source": [
    "# make prediction and print accuracy\n",
    "prediction = model.predict(X_test_tfidf)\n",
    "print(f\"Accuracy score is {accuracy_score(Y_test_tfidf, prediction):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "oTZWrjiQN8zg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.77      0.66       620\n",
      "           1       0.55      0.11      0.19       377\n",
      "           2       0.76      0.84      0.80       879\n",
      "\n",
      "    accuracy                           0.67      1876\n",
      "   macro avg       0.63      0.57      0.55      1876\n",
      "weighted avg       0.66      0.67      0.63      1876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Reg using Lexicon + Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 0.68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.75      0.68       620\n",
      "           1       0.51      0.14      0.22       377\n",
      "           2       0.74      0.86      0.79       879\n",
      "\n",
      "    accuracy                           0.68      1876\n",
      "   macro avg       0.62      0.58      0.56      1876\n",
      "weighted avg       0.65      0.68      0.64      1876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lg_lexicon = model.fit(train_feature_matrix,Y_train)\n",
    "pickle.dump(model, open(lg_model_path,'wb'))\n",
    "prediction = model.predict(test_feature_matrix)\n",
    "print(f\"Accuracy score is {accuracy_score(Y_test, prediction):.2f}\")\n",
    "print(classification_report(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_lexicon_model_path = 'Models/lg_lexicon_model.sav'\n",
    "pickle.dump(lg_lexicon, open(lg_lexicon_model_path,'wb'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tweets SA task.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
