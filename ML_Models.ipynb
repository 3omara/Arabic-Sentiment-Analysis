{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKoGGi6kLGOO"
   },
   "source": [
    "# Importing Modules and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('./Scripts')\n",
    "sys.path.append('./Files')\n",
    "sys.path.append('./Datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('pip install nltk')\n",
    "os.system('pip install openpyxl')\n",
    "os.system('pip install emot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "id": "UrjWYyRaH06H",
    "outputId": "6a81f367-faab-46f2-f597-6bd3da2443c6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\youss\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\youss\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "import openpyxl\n",
    "import emot\n",
    "import pickle\n",
    "\n",
    "# from google.colab import files\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "nltk.download('punkt')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from Sequencer import Sequencer\n",
    "from helper_fns import write_dict\n",
    "from helper_fns import read_dict\n",
    "\n",
    "from dataCleaner import clean_arabic_text\n",
    "\n",
    "import ArStemmerLib as lib\n",
    "import lexicon\n",
    "from lexicon import calc_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "K8NHuxV9Jiqq"
   },
   "outputs": [],
   "source": [
    "data_path = \"Text Preprocessing Experimentations/exp1_rtp_rl_re_cat_rl_qalsadi.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>الاوليمبياد الجايه هكون لاس ف الكليه</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>عجز الموازنه وصل ل من ناتج محل عنى لاس قلا من ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>كت نيل ف حظ هباب</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>جميع أراد تحقيق اهدافنا لكن تونس تالقت في حراس...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>الاوليمبياد نظام مختلف مواعيد مونديال مكانتش م...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet    label\n",
       "0               الاوليمبياد الجايه هكون لاس ف الكليه     none\n",
       "1  عجز الموازنه وصل ل من ناتج محل عنى لاس قلا من ...    anger\n",
       "2                                   كت نيل ف حظ هباب  sadness\n",
       "3  جميع أراد تحقيق اهدافنا لكن تونس تالقت في حراس...      joy\n",
       "4  الاوليمبياد نظام مختلف مواعيد مونديال مكانتش م...     none"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>الاوليمبياد الجايه هكون لاس ف الكليه</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>عجز الموازنه وصل ل من ناتج محل عنى لاس قلا من ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>كت نيل ف حظ هباب</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>جميع أراد تحقيق اهدافنا لكن تونس تالقت في حراس...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>الاوليمبياد نظام مختلف مواعيد مونديال مكانتش م...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet    label\n",
       "0               الاوليمبياد الجايه هكون لاس ف الكليه     none\n",
       "1  عجز الموازنه وصل ل من ناتج محل عنى لاس قلا من ...    anger\n",
       "2                                   كت نيل ف حظ هباب  sadness\n",
       "3  جميع أراد تحقيق اهدافنا لكن تونس تالقت في حراس...      joy\n",
       "4  الاوليمبياد نظام مختلف مواعيد مونديال مكانتش م...     none"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_df = pd.read_csv('Datasets/tweets_sns2.csv')\n",
    "# keep_regex = \"[Vv]odafone|VODAFONE|فودافون|[Ee]tisalat|ETISALAT|اتصالات|[Oo]range|ORANGE|اورانج|موبينيل|إتصالات|أورانج\"\n",
    "# remove_regex = \"لون\"\n",
    "# drop_indeces = tweets_df[(tweets_df['text'].str.contains(keep_regex)==False) | (tweets_df['text'].str.contains(remove_regex)==True)].index\n",
    "# tweets_df.drop(drop_indeces, inplace=True)\n",
    "# tweets= tweets_df['text'].copy()\n",
    "# tweets2 = df['tweet'].copy()\n",
    "# tokens1 = set(nltk.word_tokenize(' '.join(tweets.to_numpy().flatten())))\n",
    "# tokens2 = set(nltk.word_tokenize(' '.join(tweets2.to_numpy().flatten())))\n",
    "# def tweet_filter(tweet: str, bucket: set[str]) -> bool:\n",
    "#     tokens = set(nltk.word_tokenize(tweet))\n",
    "#     inclusion_ratio =  len(tokens.intersection(bucket)) / len(tokens)\n",
    "#     return inclusion_ratio >= 0.5\n",
    "\n",
    "# filtered_tweets = tweets.to_numpy()[[tweet_filter(x, tokens2) for x in tweets.to_numpy()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "dWmCJDvoQWET",
    "outputId": "98f72455-5352-4b51-f998-bc14483e32ac"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = sns.countplot(x='label', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6mW7GUymhLH"
   },
   "source": [
    "# Preparing Vectorized data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "vt3_NOLVnn_N"
   },
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_data = count_vec.fit_transform(df['tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "2KbRcpe5CDog"
   },
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_data = tfidf_vec.fit_transform(df['tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_data(df, embeddings_dict, embedding_padding):\n",
    "\n",
    "    sequencer = Sequencer(df['tweet'], embeddings_dict, embedding_padding)\n",
    "\n",
    "    embeddings_matrix = []\n",
    "    for tweet in df['tweet']:\n",
    "        tweet_vec = sequencer.padder(sequencer.text_to_vec(tweet))\n",
    "        embeddings_matrix.append(tweet_vec)\n",
    "    embeddings_matrix = np.array(embeddings_matrix)\n",
    "\n",
    "    embedded_data = pd.DataFrame(embeddings_matrix)\n",
    "\n",
    "    for i in range(embedding_padding):\n",
    "        embedded_data[i] =(embedded_data[i] - embedded_data[i].mean() ) / embedded_data[i].std()\n",
    "    \n",
    "    return embedded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipgram_path = \"Word Embeddings/sg_dict_exp1_5_2_100.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipgram_dict = read_dict(skipgram_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_padding = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipgram_data = embed_data(df, skipgram_dict, sg_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.666788</td>\n",
       "      <td>-0.011577</td>\n",
       "      <td>-1.735281</td>\n",
       "      <td>-0.138475</td>\n",
       "      <td>0.812687</td>\n",
       "      <td>-1.010818</td>\n",
       "      <td>-2.172168</td>\n",
       "      <td>1.948643</td>\n",
       "      <td>-2.446131</td>\n",
       "      <td>-0.868050</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.918391</td>\n",
       "      <td>-0.928069</td>\n",
       "      <td>0.122925</td>\n",
       "      <td>0.379345</td>\n",
       "      <td>-1.107691</td>\n",
       "      <td>-0.880356</td>\n",
       "      <td>-0.891465</td>\n",
       "      <td>0.792520</td>\n",
       "      <td>-0.327571</td>\n",
       "      <td>0.252153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.682653</td>\n",
       "      <td>0.302772</td>\n",
       "      <td>-0.214432</td>\n",
       "      <td>-0.608642</td>\n",
       "      <td>0.472096</td>\n",
       "      <td>0.020578</td>\n",
       "      <td>-0.778548</td>\n",
       "      <td>0.370417</td>\n",
       "      <td>0.328288</td>\n",
       "      <td>0.383659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405429</td>\n",
       "      <td>0.924907</td>\n",
       "      <td>-0.471054</td>\n",
       "      <td>-0.773833</td>\n",
       "      <td>1.014965</td>\n",
       "      <td>0.120083</td>\n",
       "      <td>0.286835</td>\n",
       "      <td>-0.277748</td>\n",
       "      <td>-1.162240</td>\n",
       "      <td>-0.113887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.015187</td>\n",
       "      <td>-0.351706</td>\n",
       "      <td>-0.285157</td>\n",
       "      <td>-0.436838</td>\n",
       "      <td>0.523360</td>\n",
       "      <td>-0.565530</td>\n",
       "      <td>-0.732081</td>\n",
       "      <td>0.086743</td>\n",
       "      <td>-0.191183</td>\n",
       "      <td>0.252277</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.918391</td>\n",
       "      <td>-0.928069</td>\n",
       "      <td>0.122925</td>\n",
       "      <td>0.379345</td>\n",
       "      <td>-1.107691</td>\n",
       "      <td>-0.880356</td>\n",
       "      <td>-0.891465</td>\n",
       "      <td>0.792520</td>\n",
       "      <td>-0.327571</td>\n",
       "      <td>0.252153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.602136</td>\n",
       "      <td>0.833356</td>\n",
       "      <td>0.497211</td>\n",
       "      <td>-0.694100</td>\n",
       "      <td>0.618843</td>\n",
       "      <td>-0.017377</td>\n",
       "      <td>-0.698268</td>\n",
       "      <td>-0.522158</td>\n",
       "      <td>0.485919</td>\n",
       "      <td>0.737001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.918391</td>\n",
       "      <td>-0.928069</td>\n",
       "      <td>0.122925</td>\n",
       "      <td>0.379345</td>\n",
       "      <td>-1.107691</td>\n",
       "      <td>-0.880356</td>\n",
       "      <td>-0.891465</td>\n",
       "      <td>0.792520</td>\n",
       "      <td>-0.327571</td>\n",
       "      <td>0.252153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.666788</td>\n",
       "      <td>-0.011577</td>\n",
       "      <td>-1.735281</td>\n",
       "      <td>-0.138475</td>\n",
       "      <td>0.812687</td>\n",
       "      <td>-1.010818</td>\n",
       "      <td>-2.172168</td>\n",
       "      <td>1.948643</td>\n",
       "      <td>-2.446131</td>\n",
       "      <td>-0.868050</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.918391</td>\n",
       "      <td>-0.928069</td>\n",
       "      <td>0.122925</td>\n",
       "      <td>0.379345</td>\n",
       "      <td>-1.107691</td>\n",
       "      <td>-0.880356</td>\n",
       "      <td>-0.891465</td>\n",
       "      <td>0.792520</td>\n",
       "      <td>-0.327571</td>\n",
       "      <td>0.252153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  1.666788 -0.011577 -1.735281 -0.138475  0.812687 -1.010818 -2.172168   \n",
       "1 -0.682653  0.302772 -0.214432 -0.608642  0.472096  0.020578 -0.778548   \n",
       "2 -0.015187 -0.351706 -0.285157 -0.436838  0.523360 -0.565530 -0.732081   \n",
       "3 -0.602136  0.833356  0.497211 -0.694100  0.618843 -0.017377 -0.698268   \n",
       "4  1.666788 -0.011577 -1.735281 -0.138475  0.812687 -1.010818 -2.172168   \n",
       "\n",
       "        7         8         9    ...       990       991       992       993  \\\n",
       "0  1.948643 -2.446131 -0.868050  ... -0.918391 -0.928069  0.122925  0.379345   \n",
       "1  0.370417  0.328288  0.383659  ...  0.405429  0.924907 -0.471054 -0.773833   \n",
       "2  0.086743 -0.191183  0.252277  ... -0.918391 -0.928069  0.122925  0.379345   \n",
       "3 -0.522158  0.485919  0.737001  ... -0.918391 -0.928069  0.122925  0.379345   \n",
       "4  1.948643 -2.446131 -0.868050  ... -0.918391 -0.928069  0.122925  0.379345   \n",
       "\n",
       "        994       995       996       997       998       999  \n",
       "0 -1.107691 -0.880356 -0.891465  0.792520 -0.327571  0.252153  \n",
       "1  1.014965  0.120083  0.286835 -0.277748 -1.162240 -0.113887  \n",
       "2 -1.107691 -0.880356 -0.891465  0.792520 -0.327571  0.252153  \n",
       "3 -1.107691 -0.880356 -0.891465  0.792520 -0.327571  0.252153  \n",
       "4 -1.107691 -0.880356 -0.891465  0.792520 -0.327571  0.252153  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skipgram_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_path = \"Word Embeddings/cb_dict_exp1_5_2_100.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_dict = read_dict(cbow_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_padding = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_data = embed_data(df, cbow_dict, cb_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.840167</td>\n",
       "      <td>-0.683009</td>\n",
       "      <td>0.277959</td>\n",
       "      <td>0.573153</td>\n",
       "      <td>-1.796662</td>\n",
       "      <td>-0.868516</td>\n",
       "      <td>0.092762</td>\n",
       "      <td>0.617435</td>\n",
       "      <td>-2.188992</td>\n",
       "      <td>-2.393079</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.986865</td>\n",
       "      <td>-0.922587</td>\n",
       "      <td>-0.304062</td>\n",
       "      <td>0.422238</td>\n",
       "      <td>-1.006567</td>\n",
       "      <td>-0.964970</td>\n",
       "      <td>-0.960525</td>\n",
       "      <td>0.868116</td>\n",
       "      <td>-0.746821</td>\n",
       "      <td>-0.111363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.176389</td>\n",
       "      <td>-1.186505</td>\n",
       "      <td>-0.619490</td>\n",
       "      <td>-0.689793</td>\n",
       "      <td>-0.709427</td>\n",
       "      <td>1.229412</td>\n",
       "      <td>-1.140765</td>\n",
       "      <td>-1.139373</td>\n",
       "      <td>1.162884</td>\n",
       "      <td>0.989851</td>\n",
       "      <td>...</td>\n",
       "      <td>1.115809</td>\n",
       "      <td>1.584304</td>\n",
       "      <td>1.022257</td>\n",
       "      <td>-1.242157</td>\n",
       "      <td>1.363939</td>\n",
       "      <td>1.043546</td>\n",
       "      <td>1.662100</td>\n",
       "      <td>-0.953393</td>\n",
       "      <td>0.384009</td>\n",
       "      <td>0.106576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.003709</td>\n",
       "      <td>-0.668620</td>\n",
       "      <td>-0.347880</td>\n",
       "      <td>-0.621316</td>\n",
       "      <td>-0.053664</td>\n",
       "      <td>0.601890</td>\n",
       "      <td>-0.708069</td>\n",
       "      <td>-0.645038</td>\n",
       "      <td>0.658213</td>\n",
       "      <td>0.695270</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.986865</td>\n",
       "      <td>-0.922587</td>\n",
       "      <td>-0.304062</td>\n",
       "      <td>0.422238</td>\n",
       "      <td>-1.006567</td>\n",
       "      <td>-0.964970</td>\n",
       "      <td>-0.960525</td>\n",
       "      <td>0.868116</td>\n",
       "      <td>-0.746821</td>\n",
       "      <td>-0.111363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.167948</td>\n",
       "      <td>0.488332</td>\n",
       "      <td>0.889346</td>\n",
       "      <td>0.460766</td>\n",
       "      <td>0.027175</td>\n",
       "      <td>-0.586057</td>\n",
       "      <td>0.340872</td>\n",
       "      <td>0.421808</td>\n",
       "      <td>-0.419765</td>\n",
       "      <td>-0.314134</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.986865</td>\n",
       "      <td>-0.922587</td>\n",
       "      <td>-0.304062</td>\n",
       "      <td>0.422238</td>\n",
       "      <td>-1.006567</td>\n",
       "      <td>-0.964970</td>\n",
       "      <td>-0.960525</td>\n",
       "      <td>0.868116</td>\n",
       "      <td>-0.746821</td>\n",
       "      <td>-0.111363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.840167</td>\n",
       "      <td>-0.683009</td>\n",
       "      <td>0.277959</td>\n",
       "      <td>0.573153</td>\n",
       "      <td>-1.796662</td>\n",
       "      <td>-0.868516</td>\n",
       "      <td>0.092762</td>\n",
       "      <td>0.617435</td>\n",
       "      <td>-2.188992</td>\n",
       "      <td>-2.393079</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.986865</td>\n",
       "      <td>-0.922587</td>\n",
       "      <td>-0.304062</td>\n",
       "      <td>0.422238</td>\n",
       "      <td>-1.006567</td>\n",
       "      <td>-0.964970</td>\n",
       "      <td>-0.960525</td>\n",
       "      <td>0.868116</td>\n",
       "      <td>-0.746821</td>\n",
       "      <td>-0.111363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  3.840167 -0.683009  0.277959  0.573153 -1.796662 -0.868516  0.092762   \n",
       "1  0.176389 -1.186505 -0.619490 -0.689793 -0.709427  1.229412 -1.140765   \n",
       "2 -0.003709 -0.668620 -0.347880 -0.621316 -0.053664  0.601890 -0.708069   \n",
       "3 -0.167948  0.488332  0.889346  0.460766  0.027175 -0.586057  0.340872   \n",
       "4  3.840167 -0.683009  0.277959  0.573153 -1.796662 -0.868516  0.092762   \n",
       "\n",
       "        7         8         9    ...       990       991       992       993  \\\n",
       "0  0.617435 -2.188992 -2.393079  ... -0.986865 -0.922587 -0.304062  0.422238   \n",
       "1 -1.139373  1.162884  0.989851  ...  1.115809  1.584304  1.022257 -1.242157   \n",
       "2 -0.645038  0.658213  0.695270  ... -0.986865 -0.922587 -0.304062  0.422238   \n",
       "3  0.421808 -0.419765 -0.314134  ... -0.986865 -0.922587 -0.304062  0.422238   \n",
       "4  0.617435 -2.188992 -2.393079  ... -0.986865 -0.922587 -0.304062  0.422238   \n",
       "\n",
       "        994       995       996       997       998       999  \n",
       "0 -1.006567 -0.964970 -0.960525  0.868116 -0.746821 -0.111363  \n",
       "1  1.363939  1.043546  1.662100 -0.953393  0.384009  0.106576  \n",
       "2 -1.006567 -0.964970 -0.960525  0.868116 -0.746821 -0.111363  \n",
       "3 -1.006567 -0.964970 -0.960525  0.868116 -0.746821 -0.111363  \n",
       "4 -1.006567 -0.964970 -0.960525  0.868116 -0.746821 -0.111363  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8EB9aBqUlk_I"
   },
   "source": [
    "# Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "08yU2oHFloYJ"
   },
   "outputs": [],
   "source": [
    "X_train_tfidf,X_test_tfidf,Y_train_tfidf,Y_test_tfidf = train_test_split(tfidf_data, df['label'], test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "wBDnCyIxCcrm"
   },
   "outputs": [],
   "source": [
    "X_train_count,X_test_count,Y_train_count,Y_test_count = train_test_split(count_data, df['label'], test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sg ,X_test_sg ,Y_train_sg ,Y_test_sg  = train_test_split(skipgram_data, df['label'], test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cb ,X_test_cb ,Y_train_cb ,Y_test_cb  = train_test_split(cbow_data, df['label'], test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train ,X_test ,Y_train ,Y_test  = train_test_split(df['tweet'], df['label'], test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "923         fear\n",
       "8528        none\n",
       "3121        fear\n",
       "3487    sympathy\n",
       "5856        none\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le = LabelEncoder()\n",
    "# Y_test_tfidf = le.fit_transform(Y_test_tfidf)\n",
    "# Y_test_count = le.fit_transform(Y_test_count)\n",
    "# Y_test = le.fit_transform(Y_test)\n",
    "# Y_train_tfidf = le.fit_transform(Y_train_tfidf)\n",
    "# Y_train_count = le.fit_transform(Y_train_count)\n",
    "# Y_train = le.fit_transform(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NkPLDKRLYqJZ"
   },
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexicon + Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the lexicon\n",
    "tweet_train_lex = []\n",
    "for tweet in X_train:\n",
    "    tweet_train_lex.append(calc_lexicon(u\"%s\" %tweet))\n",
    "\n",
    "tweet_test_lex = []\n",
    "for tweet in X_test:\n",
    "    tweet_test_lex.append(calc_lexicon(u\"%s\" %tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "CFdraTg7YvU8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2514x2 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2284 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "tweet_lex_train_sparse = csr_matrix(tweet_train_lex)\n",
    "tweet_lex_test_sparse = csr_matrix(tweet_test_lex)\n",
    "tweet_lex_test_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "DQRPxYCmYxQg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2514x18066 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 33425 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_matrix = hstack((X_train_count, tweet_lex_train_sparse))\n",
    "test_feature_matrix = hstack((X_test_count, tweet_lex_test_sparse))\n",
    "test_feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "OvrKyk5PZqm8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 62.88782816229117%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.64      0.69      0.67       371\n",
      "        fear       0.82      0.84      0.83       292\n",
      "         joy       0.56      0.35      0.43       307\n",
      "        love       0.60      0.80      0.69       281\n",
      "        none       0.53      0.90      0.66       395\n",
      "     sadness       0.49      0.33      0.39       301\n",
      "    surprise       0.71      0.24      0.35       279\n",
      "    sympathy       0.80      0.80      0.80       288\n",
      "\n",
      "    accuracy                           0.63      2514\n",
      "   macro avg       0.64      0.62      0.60      2514\n",
      "weighted avg       0.64      0.63      0.61      2514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_lexicon = cl.fit(train_feature_matrix,Y_train)\n",
    "predicted = cl.predict(test_feature_matrix)\n",
    "acc = accuracy_score(Y_test,predicted)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_lex_model_path = 'Models/nb_lexicon_model.sav'\n",
    "pickle.dump(nb_lexicon, open(nb_lex_model_path,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNju2dCSnfow"
   },
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "tovTo0rFoKFr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 60.501193317422434%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.63      0.63      0.63       371\n",
      "        fear       0.81      0.84      0.82       292\n",
      "         joy       0.59      0.33      0.42       307\n",
      "        love       0.60      0.79      0.68       281\n",
      "        none       0.44      0.94      0.60       395\n",
      "     sadness       0.58      0.29      0.39       301\n",
      "    surprise       0.86      0.16      0.27       279\n",
      "    sympathy       0.87      0.74      0.80       288\n",
      "\n",
      "    accuracy                           0.61      2514\n",
      "   macro avg       0.67      0.59      0.58      2514\n",
      "weighted avg       0.66      0.61      0.58      2514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_tfidf = cl.fit(X_train_tfidf, Y_train_tfidf)\n",
    "p = cl.predict(X_test_tfidf)\n",
    "acc = accuracy_score(Y_test_tfidf,p)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_tfidf_model_path = 'Models/nb_tfidf_model.sav'\n",
    "pickle.dump(nb_tfidf, open(nb_tfidf_model_path,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexicon + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2514x18066 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 33425 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_matrix_tf = hstack((X_train_tfidf, tweet_lex_train_sparse))\n",
    "test_feature_matrix_tf = hstack((X_test_tfidf, tweet_lex_test_sparse))\n",
    "test_feature_matrix_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 54.97215592680986%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.42      0.81      0.55       371\n",
      "        fear       0.84      0.67      0.75       292\n",
      "         joy       0.51      0.38      0.43       307\n",
      "        love       0.52      0.77      0.62       281\n",
      "        none       0.51      0.73      0.60       395\n",
      "     sadness       0.47      0.20      0.28       301\n",
      "    surprise       0.88      0.10      0.19       279\n",
      "    sympathy       0.89      0.60      0.72       288\n",
      "\n",
      "    accuracy                           0.55      2514\n",
      "   macro avg       0.63      0.53      0.52      2514\n",
      "weighted avg       0.62      0.55      0.52      2514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_lex_tfidf = cl.fit(train_feature_matrix_tf,Y_train)\n",
    "predicted = cl.predict(test_feature_matrix_tf)\n",
    "acc = accuracy_score(Y_test,predicted)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_lex_tfidf_model_path = 'Models/nb_lex_tfidf_model.sav'\n",
    "pickle.dump(nb_lex_tfidf, open(nb_lex_tfidf_model_path,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOswlrtZJK_G"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "4ZDYb8IzJT7S"
   },
   "outputs": [],
   "source": [
    "lg =  LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "EoBqNWdbJWB6"
   },
   "outputs": [],
   "source": [
    "# make param grid\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# create and fit the model\n",
    "model = GridSearchCV(lg, param_grid, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "Xq49spN8JslI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(max_iter=1000),\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(max_iter=1000),\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(max_iter=1000),\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10, 100]})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_tfidf,Y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "QWb51vfLN3ND"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 65.11535401750199%\n"
     ]
    }
   ],
   "source": [
    "# make prediction and print accuracy\n",
    "prediction = model.predict(X_test_tfidf)\n",
    "print ('accuracy = '+str(accuracy_score(Y_test_tfidf, prediction)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "oTZWrjiQN8zg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.56      0.73      0.64       371\n",
      "        fear       0.98      0.83      0.90       292\n",
      "         joy       0.52      0.46      0.49       307\n",
      "        love       0.69      0.71      0.70       281\n",
      "        none       0.61      0.89      0.72       395\n",
      "     sadness       0.48      0.37      0.42       301\n",
      "    surprise       0.67      0.36      0.47       279\n",
      "    sympathy       0.82      0.77      0.79       288\n",
      "\n",
      "    accuracy                           0.65      2514\n",
      "   macro avg       0.67      0.64      0.64      2514\n",
      "weighted avg       0.66      0.65      0.64      2514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_model_path = 'Models/exp1_lg_tfidf_model.sav'\n",
    "pickle.dump(model, open(lg_model_path,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexicon + Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 0.65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.66      0.68      0.67       371\n",
      "        fear       0.98      0.83      0.90       292\n",
      "         joy       0.49      0.54      0.51       307\n",
      "        love       0.70      0.69      0.70       281\n",
      "        none       0.61      0.89      0.73       395\n",
      "     sadness       0.46      0.36      0.40       301\n",
      "    surprise       0.61      0.39      0.48       279\n",
      "    sympathy       0.79      0.76      0.78       288\n",
      "\n",
      "    accuracy                           0.65      2514\n",
      "   macro avg       0.66      0.64      0.64      2514\n",
      "weighted avg       0.66      0.65      0.65      2514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lg_lexicon = model.fit(train_feature_matrix,Y_train)\n",
    "prediction = model.predict(test_feature_matrix)\n",
    "print(f\"Accuracy score is {accuracy_score(Y_test, prediction):.2f}\")\n",
    "print(classification_report(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_lexicon_model_path = 'Models/lg_lexicon_model.sav'\n",
    "pickle.dump(lg_lexicon, open(lg_lexicon_model_path,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complement Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNB = ComplementNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ComplementNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ComplementNB</label><div class=\"sk-toggleable__content\"><pre>ComplementNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ComplementNB()"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNB.fit(X_train_tfidf, Y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 63.32537788385044%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.71      0.60      0.65       371\n",
      "        fear       0.76      0.91      0.83       292\n",
      "         joy       0.56      0.35      0.43       307\n",
      "        love       0.59      0.79      0.67       281\n",
      "        none       0.54      0.88      0.67       395\n",
      "     sadness       0.63      0.28      0.38       301\n",
      "    surprise       0.63      0.31      0.42       279\n",
      "    sympathy       0.71      0.89      0.79       288\n",
      "\n",
      "    accuracy                           0.63      2514\n",
      "   macro avg       0.64      0.63      0.61      2514\n",
      "weighted avg       0.64      0.63      0.61      2514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = CNB.predict(X_test_tfidf)\n",
    "acc = accuracy_score(Y_test_tfidf,predicted)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test_tfidf,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_SVC = SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip-Gram Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 49.721559268098645%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.36      0.57      0.44       371\n",
      "        fear       0.73      0.67      0.70       292\n",
      "         joy       0.33      0.26      0.29       307\n",
      "        love       0.57      0.58      0.58       281\n",
      "        none       0.54      0.86      0.66       395\n",
      "     sadness       0.22      0.10      0.14       301\n",
      "    surprise       0.51      0.23      0.31       279\n",
      "    sympathy       0.67      0.59      0.62       288\n",
      "\n",
      "    accuracy                           0.50      2514\n",
      "   macro avg       0.49      0.48      0.47      2514\n",
      "weighted avg       0.49      0.50      0.47      2514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_embedding = SVM_SVC.fit(X_train_sg,Y_train_sg)\n",
    "predicted = svc_embedding.predict(X_test_sg)\n",
    "acc = accuracy_score(Y_test_sg,predicted)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test_sg,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBOW Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 41.527446300715994%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.29      0.52      0.37       371\n",
      "        fear       0.58      0.58      0.58       292\n",
      "         joy       0.27      0.22      0.24       307\n",
      "        love       0.36      0.39      0.37       281\n",
      "        none       0.53      0.81      0.64       395\n",
      "     sadness       0.20      0.08      0.11       301\n",
      "    surprise       0.42      0.16      0.23       279\n",
      "    sympathy       0.63      0.41      0.50       288\n",
      "\n",
      "    accuracy                           0.42      2514\n",
      "   macro avg       0.41      0.40      0.38      2514\n",
      "weighted avg       0.41      0.42      0.39      2514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_embedding = SVM_SVC.fit(X_train_cb,Y_train_cb)\n",
    "predicted = svc_embedding.predict(X_test_cb)\n",
    "acc = accuracy_score(Y_test_cb,predicted)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test_cb,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 64.55847255369929%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.52      0.76      0.62       371\n",
      "        fear       0.99      0.82      0.89       292\n",
      "         joy       0.50      0.43      0.47       307\n",
      "        love       0.75      0.67      0.71       281\n",
      "        none       0.60      0.93      0.73       395\n",
      "     sadness       0.49      0.40      0.44       301\n",
      "    surprise       0.74      0.30      0.43       279\n",
      "    sympathy       0.84      0.73      0.78       288\n",
      "\n",
      "    accuracy                           0.65      2514\n",
      "   macro avg       0.68      0.63      0.63      2514\n",
      "weighted avg       0.67      0.65      0.64      2514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_tfidf = SVM_SVC.fit(X_train_tfidf,Y_train_tfidf)\n",
    "predicted = svc_tfidf.predict(X_test_tfidf)\n",
    "acc = accuracy_score(Y_test_tfidf,predicted)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test_tfidf,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 62.171837708830544%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.53      0.67      0.59       371\n",
      "        fear       0.99      0.80      0.89       292\n",
      "         joy       0.42      0.47      0.44       307\n",
      "        love       0.74      0.65      0.69       281\n",
      "        none       0.58      0.95      0.72       395\n",
      "     sadness       0.50      0.32      0.39       301\n",
      "    surprise       0.70      0.29      0.41       279\n",
      "    sympathy       0.78      0.70      0.74       288\n",
      "\n",
      "    accuracy                           0.62      2514\n",
      "   macro avg       0.65      0.61      0.61      2514\n",
      "weighted avg       0.64      0.62      0.61      2514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_count = SVM_SVC.fit(X_train_count,Y_train_count)\n",
    "predicted = svc_count.predict(X_test_count)\n",
    "acc = accuracy_score(Y_test_count,predicted)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test_count,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(in_dim, out_dim),\n",
    "    tf.keras.layers.Dense(out_dim, )\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tweets SA task.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
