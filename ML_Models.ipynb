{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKoGGi6kLGOO"
   },
   "source": [
    "# Importing Modules and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('./Scripts')\n",
    "sys.path.append('./Files')\n",
    "sys.path.append('./Datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('pip install nltk')\n",
    "os.system('pip install openpyxl')\n",
    "os.system('pip install emot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "id": "UrjWYyRaH06H",
    "outputId": "6a81f367-faab-46f2-f597-6bd3da2443c6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\youss\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "import openpyxl\n",
    "import emot\n",
    "import pickle\n",
    "\n",
    "# from google.colab import files\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "nltk.download('punkt')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from Sequencer import Sequencer\n",
    "from helper_fns import write_dict\n",
    "from helper_fns import read_dict\n",
    "\n",
    "from dataCleaner import clean_arabic_text\n",
    "\n",
    "import ArStemmerLib as lib\n",
    "import lexicon\n",
    "from lexicon import calc_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "K8NHuxV9Jiqq"
   },
   "outputs": [],
   "source": [
    "data_path = \"Text Preprocessing Experimentations/exp1_train_rtp_rl_re_cat_rl_qalsadi.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_df = pd.read_csv('Datasets/tweets_sns2.csv')\n",
    "# keep_regex = \"[Vv]odafone|VODAFONE|فودافون|[Ee]tisalat|ETISALAT|اتصالات|[Oo]range|ORANGE|اورانج|موبينيل|إتصالات|أورانج\"\n",
    "# remove_regex = \"لون\"\n",
    "# drop_indeces = tweets_df[(tweets_df['text'].str.contains(keep_regex)==False) | (tweets_df['text'].str.contains(remove_regex)==True)].index\n",
    "# tweets_df.drop(drop_indeces, inplace=True)\n",
    "# tweets= tweets_df['text'].copy()\n",
    "# tweets2 = df['tweet'].copy()\n",
    "# tokens1 = set(nltk.word_tokenize(' '.join(tweets.to_numpy().flatten())))\n",
    "# tokens2 = set(nltk.word_tokenize(' '.join(tweets2.to_numpy().flatten())))\n",
    "# def tweet_filter(tweet: str, bucket: set[str]) -> bool:\n",
    "#     tokens = set(nltk.word_tokenize(tweet))\n",
    "#     inclusion_ratio =  len(tokens.intersection(bucket)) / len(tokens)\n",
    "#     return inclusion_ratio >= 0.5\n",
    "\n",
    "# filtered_tweets = tweets.to_numpy()[[tweet_filter(x, tokens2) for x in tweets.to_numpy()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "dWmCJDvoQWET",
    "outputId": "98f72455-5352-4b51-f998-bc14483e32ac"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = sns.countplot(x='sentiment', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6mW7GUymhLH"
   },
   "source": [
    "# Preparing Vectorized data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "vt3_NOLVnn_N"
   },
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_data = count_vec.fit_transform(df['tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "2KbRcpe5CDog"
   },
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_data = tfidf_vec.fit_transform(df['tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_data(df, embeddings_dict, embedding_padding):\n",
    "\n",
    "    sequencer = Sequencer(df['tweet'], embeddings_dict, embedding_padding)\n",
    "\n",
    "    embeddings_matrix = []\n",
    "    for tweet in df['tweet']:\n",
    "        tweet_vec = sequencer.padder(sequencer.text_to_vec(tweet))\n",
    "        embeddings_matrix.append(tweet_vec)\n",
    "    embeddings_matrix = np.array(embeddings_matrix)\n",
    "\n",
    "    embedded_data = pd.DataFrame(embeddings_matrix)\n",
    "\n",
    "    for i in range(embedding_padding):\n",
    "        embedded_data[i] =(embedded_data[i] - embedded_data[i].mean() ) / embedded_data[i].std()\n",
    "    \n",
    "    return embedded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipgram_path = \"Word Embeddings/sg_dict_exp1_5_2_100.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipgram_dict = read_dict(skipgram_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_padding = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipgram_data = embed_data(df, skipgram_dict, sg_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.271038</td>\n",
       "      <td>-1.527171</td>\n",
       "      <td>1.474904</td>\n",
       "      <td>0.631825</td>\n",
       "      <td>-0.723927</td>\n",
       "      <td>1.081868</td>\n",
       "      <td>-0.939506</td>\n",
       "      <td>-1.151725</td>\n",
       "      <td>1.179911</td>\n",
       "      <td>0.807985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340937</td>\n",
       "      <td>0.394804</td>\n",
       "      <td>0.340109</td>\n",
       "      <td>-0.425280</td>\n",
       "      <td>0.341927</td>\n",
       "      <td>0.288703</td>\n",
       "      <td>0.168849</td>\n",
       "      <td>-0.262509</td>\n",
       "      <td>0.545395</td>\n",
       "      <td>-0.910550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.041479</td>\n",
       "      <td>0.789409</td>\n",
       "      <td>0.428717</td>\n",
       "      <td>0.480546</td>\n",
       "      <td>-0.184204</td>\n",
       "      <td>-0.129974</td>\n",
       "      <td>-0.132827</td>\n",
       "      <td>0.367455</td>\n",
       "      <td>0.065133</td>\n",
       "      <td>-0.617037</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.946921</td>\n",
       "      <td>-0.947947</td>\n",
       "      <td>-0.946971</td>\n",
       "      <td>0.795187</td>\n",
       "      <td>-0.947575</td>\n",
       "      <td>-0.946875</td>\n",
       "      <td>-0.930535</td>\n",
       "      <td>0.949500</td>\n",
       "      <td>-0.940034</td>\n",
       "      <td>0.788748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.130396</td>\n",
       "      <td>-0.650507</td>\n",
       "      <td>-0.487321</td>\n",
       "      <td>-1.149445</td>\n",
       "      <td>1.986815</td>\n",
       "      <td>-0.590338</td>\n",
       "      <td>0.106037</td>\n",
       "      <td>0.654020</td>\n",
       "      <td>-0.914656</td>\n",
       "      <td>-0.779677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.256357</td>\n",
       "      <td>0.431265</td>\n",
       "      <td>-0.353342</td>\n",
       "      <td>0.241366</td>\n",
       "      <td>0.369325</td>\n",
       "      <td>0.245575</td>\n",
       "      <td>-0.260409</td>\n",
       "      <td>0.475285</td>\n",
       "      <td>0.259021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.349906</td>\n",
       "      <td>0.751071</td>\n",
       "      <td>0.408079</td>\n",
       "      <td>-0.914289</td>\n",
       "      <td>0.639183</td>\n",
       "      <td>-0.211042</td>\n",
       "      <td>0.386194</td>\n",
       "      <td>0.292230</td>\n",
       "      <td>-0.440142</td>\n",
       "      <td>0.066203</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.946921</td>\n",
       "      <td>-0.947947</td>\n",
       "      <td>-0.946971</td>\n",
       "      <td>0.795187</td>\n",
       "      <td>-0.947575</td>\n",
       "      <td>-0.946875</td>\n",
       "      <td>-0.930535</td>\n",
       "      <td>0.949500</td>\n",
       "      <td>-0.940034</td>\n",
       "      <td>0.788748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.095861</td>\n",
       "      <td>0.839597</td>\n",
       "      <td>0.557592</td>\n",
       "      <td>-0.331591</td>\n",
       "      <td>0.954286</td>\n",
       "      <td>-0.622397</td>\n",
       "      <td>0.431203</td>\n",
       "      <td>0.561547</td>\n",
       "      <td>-0.489602</td>\n",
       "      <td>0.306158</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.946921</td>\n",
       "      <td>-0.947947</td>\n",
       "      <td>-0.946971</td>\n",
       "      <td>0.795187</td>\n",
       "      <td>-0.947575</td>\n",
       "      <td>-0.946875</td>\n",
       "      <td>-0.930535</td>\n",
       "      <td>0.949500</td>\n",
       "      <td>-0.940034</td>\n",
       "      <td>0.788748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  1.271038 -1.527171  1.474904  0.631825 -0.723927  1.081868 -0.939506   \n",
       "1 -0.041479  0.789409  0.428717  0.480546 -0.184204 -0.129974 -0.132827   \n",
       "2 -1.130396 -0.650507 -0.487321 -1.149445  1.986815 -0.590338  0.106037   \n",
       "3 -0.349906  0.751071  0.408079 -0.914289  0.639183 -0.211042  0.386194   \n",
       "4 -0.095861  0.839597  0.557592 -0.331591  0.954286 -0.622397  0.431203   \n",
       "\n",
       "        7         8         9    ...       990       991       992       993  \\\n",
       "0 -1.151725  1.179911  0.807985  ...  0.340937  0.394804  0.340109 -0.425280   \n",
       "1  0.367455  0.065133 -0.617037  ... -0.946921 -0.947947 -0.946971  0.795187   \n",
       "2  0.654020 -0.914656 -0.779677  ...  0.371212  0.256357  0.431265 -0.353342   \n",
       "3  0.292230 -0.440142  0.066203  ... -0.946921 -0.947947 -0.946971  0.795187   \n",
       "4  0.561547 -0.489602  0.306158  ... -0.946921 -0.947947 -0.946971  0.795187   \n",
       "\n",
       "        994       995       996       997       998       999  \n",
       "0  0.341927  0.288703  0.168849 -0.262509  0.545395 -0.910550  \n",
       "1 -0.947575 -0.946875 -0.930535  0.949500 -0.940034  0.788748  \n",
       "2  0.241366  0.369325  0.245575 -0.260409  0.475285  0.259021  \n",
       "3 -0.947575 -0.946875 -0.930535  0.949500 -0.940034  0.788748  \n",
       "4 -0.947575 -0.946875 -0.930535  0.949500 -0.940034  0.788748  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skipgram_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_path = \"Word Embeddings/cb_dict_exp1_5_2_100.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_dict = read_dict(cbow_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_padding = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_data = embed_data(df, cbow_dict, cb_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.466028</td>\n",
       "      <td>-1.542237</td>\n",
       "      <td>1.587045</td>\n",
       "      <td>1.498302</td>\n",
       "      <td>-1.385265</td>\n",
       "      <td>1.404378</td>\n",
       "      <td>-1.382232</td>\n",
       "      <td>-1.415088</td>\n",
       "      <td>1.426477</td>\n",
       "      <td>1.365116</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.393273</td>\n",
       "      <td>-0.369322</td>\n",
       "      <td>-0.404756</td>\n",
       "      <td>0.303971</td>\n",
       "      <td>-0.399949</td>\n",
       "      <td>-0.431631</td>\n",
       "      <td>-0.437717</td>\n",
       "      <td>0.453755</td>\n",
       "      <td>-0.314152</td>\n",
       "      <td>-1.952366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.638552</td>\n",
       "      <td>-0.493738</td>\n",
       "      <td>0.676737</td>\n",
       "      <td>0.910908</td>\n",
       "      <td>-0.650437</td>\n",
       "      <td>0.624788</td>\n",
       "      <td>-0.694716</td>\n",
       "      <td>-0.560525</td>\n",
       "      <td>0.659683</td>\n",
       "      <td>0.508297</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.761202</td>\n",
       "      <td>-0.761376</td>\n",
       "      <td>-0.760584</td>\n",
       "      <td>0.690160</td>\n",
       "      <td>-0.760800</td>\n",
       "      <td>-0.762038</td>\n",
       "      <td>-0.761485</td>\n",
       "      <td>0.761840</td>\n",
       "      <td>-0.763015</td>\n",
       "      <td>-0.367676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.208991</td>\n",
       "      <td>0.998348</td>\n",
       "      <td>-1.229029</td>\n",
       "      <td>-1.476950</td>\n",
       "      <td>1.347140</td>\n",
       "      <td>-1.156843</td>\n",
       "      <td>1.063357</td>\n",
       "      <td>1.150610</td>\n",
       "      <td>-1.250804</td>\n",
       "      <td>-1.139106</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.462794</td>\n",
       "      <td>-0.525928</td>\n",
       "      <td>-0.426347</td>\n",
       "      <td>0.440855</td>\n",
       "      <td>-0.528031</td>\n",
       "      <td>-0.459367</td>\n",
       "      <td>-0.507294</td>\n",
       "      <td>0.535991</td>\n",
       "      <td>-0.433973</td>\n",
       "      <td>0.701467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.207738</td>\n",
       "      <td>0.251813</td>\n",
       "      <td>-0.099799</td>\n",
       "      <td>-0.617206</td>\n",
       "      <td>0.270799</td>\n",
       "      <td>-0.176866</td>\n",
       "      <td>0.223796</td>\n",
       "      <td>0.201109</td>\n",
       "      <td>-0.234088</td>\n",
       "      <td>-0.172313</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.761202</td>\n",
       "      <td>-0.761376</td>\n",
       "      <td>-0.760584</td>\n",
       "      <td>0.690160</td>\n",
       "      <td>-0.760800</td>\n",
       "      <td>-0.762038</td>\n",
       "      <td>-0.761485</td>\n",
       "      <td>0.761840</td>\n",
       "      <td>-0.763015</td>\n",
       "      <td>-0.367676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.343595</td>\n",
       "      <td>-0.214957</td>\n",
       "      <td>0.398737</td>\n",
       "      <td>0.136776</td>\n",
       "      <td>-0.151041</td>\n",
       "      <td>0.243066</td>\n",
       "      <td>-0.255637</td>\n",
       "      <td>-0.249155</td>\n",
       "      <td>0.253996</td>\n",
       "      <td>0.381233</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.761202</td>\n",
       "      <td>-0.761376</td>\n",
       "      <td>-0.760584</td>\n",
       "      <td>0.690160</td>\n",
       "      <td>-0.760800</td>\n",
       "      <td>-0.762038</td>\n",
       "      <td>-0.761485</td>\n",
       "      <td>0.761840</td>\n",
       "      <td>-0.763015</td>\n",
       "      <td>-0.367676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  1.466028 -1.542237  1.587045  1.498302 -1.385265  1.404378 -1.382232   \n",
       "1  0.638552 -0.493738  0.676737  0.910908 -0.650437  0.624788 -0.694716   \n",
       "2 -1.208991  0.998348 -1.229029 -1.476950  1.347140 -1.156843  1.063357   \n",
       "3 -0.207738  0.251813 -0.099799 -0.617206  0.270799 -0.176866  0.223796   \n",
       "4  0.343595 -0.214957  0.398737  0.136776 -0.151041  0.243066 -0.255637   \n",
       "\n",
       "        7         8         9    ...       990       991       992       993  \\\n",
       "0 -1.415088  1.426477  1.365116  ... -0.393273 -0.369322 -0.404756  0.303971   \n",
       "1 -0.560525  0.659683  0.508297  ... -0.761202 -0.761376 -0.760584  0.690160   \n",
       "2  1.150610 -1.250804 -1.139106  ... -0.462794 -0.525928 -0.426347  0.440855   \n",
       "3  0.201109 -0.234088 -0.172313  ... -0.761202 -0.761376 -0.760584  0.690160   \n",
       "4 -0.249155  0.253996  0.381233  ... -0.761202 -0.761376 -0.760584  0.690160   \n",
       "\n",
       "        994       995       996       997       998       999  \n",
       "0 -0.399949 -0.431631 -0.437717  0.453755 -0.314152 -1.952366  \n",
       "1 -0.760800 -0.762038 -0.761485  0.761840 -0.763015 -0.367676  \n",
       "2 -0.528031 -0.459367 -0.507294  0.535991 -0.433973  0.701467  \n",
       "3 -0.760800 -0.762038 -0.761485  0.761840 -0.763015 -0.367676  \n",
       "4 -0.760800 -0.762038 -0.761485  0.761840 -0.763015 -0.367676  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8EB9aBqUlk_I"
   },
   "source": [
    "# Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "08yU2oHFloYJ"
   },
   "outputs": [],
   "source": [
    "X_train_tfidf,X_test_tfidf,Y_train_tfidf,Y_test_tfidf = train_test_split(tfidf_data, df['sentiment'], test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "wBDnCyIxCcrm"
   },
   "outputs": [],
   "source": [
    "X_train_count,X_test_count,Y_train_count,Y_test_count = train_test_split(count_data, df['sentiment'], test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sg ,X_test_sg ,Y_train_sg ,Y_test_sg  = train_test_split(skipgram_data, df['sentiment'], test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cb ,X_test_cb ,Y_train_cb ,Y_test_cb  = train_test_split(cbow_data, df['sentiment'], test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train ,X_test ,Y_train ,Y_test  = train_test_split(df['tweet'], df['sentiment'], test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6333    positive\n",
       "4891    positive\n",
       "1050     neutral\n",
       "5629     neutral\n",
       "6434     neutral\n",
       "Name: sentiment, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le = LabelEncoder()\n",
    "# Y_test_tfidf = le.fit_transform(Y_test_tfidf)\n",
    "# Y_test_count = le.fit_transform(Y_test_count)\n",
    "# Y_test = le.fit_transform(Y_test)\n",
    "# Y_train_tfidf = le.fit_transform(Y_train_tfidf)\n",
    "# Y_train_count = le.fit_transform(Y_train_count)\n",
    "# Y_train = le.fit_transform(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NkPLDKRLYqJZ"
   },
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexicon + Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the lexicon\n",
    "tweet_train_lex = []\n",
    "for tweet in X_train:\n",
    "    tweet_train_lex.append(calc_lexicon(u\"%s\" %tweet))\n",
    "\n",
    "tweet_test_lex = []\n",
    "for tweet in X_test:\n",
    "    tweet_test_lex.append(calc_lexicon(u\"%s\" %tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "CFdraTg7YvU8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1454x2 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1237 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "tweet_lex_train_sparse = csr_matrix(tweet_train_lex)\n",
    "tweet_lex_test_sparse = csr_matrix(tweet_test_lex)\n",
    "tweet_lex_test_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "DQRPxYCmYxQg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1454x14030 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 18586 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_matrix = hstack((X_train_count, tweet_lex_train_sparse))\n",
    "test_feature_matrix = hstack((X_test_count, tweet_lex_test_sparse))\n",
    "test_feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "OvrKyk5PZqm8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 61.27922971114168%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.77      0.71       682\n",
      "     neutral       0.36      0.19      0.25       362\n",
      "    positive       0.64      0.73      0.68       410\n",
      "\n",
      "    accuracy                           0.61      1454\n",
      "   macro avg       0.55      0.56      0.55      1454\n",
      "weighted avg       0.58      0.61      0.59      1454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_lexicon = cl.fit(train_feature_matrix,Y_train)\n",
    "predicted = cl.predict(test_feature_matrix)\n",
    "acc = accuracy_score(Y_test,predicted)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_lex_model_path = 'Models/nb_lexicon_model.sav'\n",
    "pickle.dump(nb_lexicon, open(nb_lex_model_path,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNju2dCSnfow"
   },
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "tovTo0rFoKFr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 61.141678129298484%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.95      0.72       682\n",
      "     neutral       0.58      0.03      0.06       362\n",
      "    positive       0.75      0.56      0.64       410\n",
      "\n",
      "    accuracy                           0.61      1454\n",
      "   macro avg       0.63      0.51      0.47      1454\n",
      "weighted avg       0.62      0.61      0.53      1454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_tfidf = cl.fit(X_train_tfidf, Y_train_tfidf)\n",
    "p = cl.predict(X_test_tfidf)\n",
    "acc = accuracy_score(Y_test_tfidf,p)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_tfidf_model_path = 'Models/nb_tfidf_model.sav'\n",
    "pickle.dump(nb_tfidf, open(nb_tfidf_model_path,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexicon + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1454x14030 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 18586 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_matrix_tf = hstack((X_train_tfidf, tweet_lex_train_sparse))\n",
    "test_feature_matrix_tf = hstack((X_test_tfidf, tweet_lex_test_sparse))\n",
    "test_feature_matrix_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 62.17331499312242%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.90      0.73       682\n",
      "     neutral       0.52      0.03      0.06       362\n",
      "    positive       0.65      0.68      0.66       410\n",
      "\n",
      "    accuracy                           0.62      1454\n",
      "   macro avg       0.59      0.54      0.48      1454\n",
      "weighted avg       0.60      0.62      0.54      1454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_lex_tfidf = cl.fit(train_feature_matrix_tf,Y_train)\n",
    "predicted = cl.predict(test_feature_matrix_tf)\n",
    "acc = accuracy_score(Y_test,predicted)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_lex_tfidf_model_path = 'Models/nb_lex_tfidf_model.sav'\n",
    "pickle.dump(nb_lex_tfidf, open(nb_lex_tfidf_model_path,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOswlrtZJK_G"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "4ZDYb8IzJT7S"
   },
   "outputs": [],
   "source": [
    "lg =  LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "EoBqNWdbJWB6"
   },
   "outputs": [],
   "source": [
    "# make param grid\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# create and fit the model\n",
    "model = GridSearchCV(lg, param_grid, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_model_path = 'Models/exp1_lg_tfidf_model.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "Xq49spN8JslI"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train_tfidf,Y_train_tfidf)\n",
    "pickle.dump(model, open(lg_model_path,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "QWb51vfLN3ND"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 62.379642365887214%\n"
     ]
    }
   ],
   "source": [
    "# make prediction and print accuracy\n",
    "prediction = model.predict(X_test_tfidf)\n",
    "print ('accuracy = '+str(accuracy_score(Y_test_tfidf, prediction)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "oTZWrjiQN8zg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.87      0.72       682\n",
      "     neutral       0.42      0.14      0.21       362\n",
      "    positive       0.72      0.64      0.68       410\n",
      "\n",
      "    accuracy                           0.62      1454\n",
      "   macro avg       0.59      0.55      0.54      1454\n",
      "weighted avg       0.60      0.62      0.58      1454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexicon + Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 0.61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.77      0.71       682\n",
      "     neutral       0.43      0.20      0.27       362\n",
      "    positive       0.62      0.72      0.67       410\n",
      "\n",
      "    accuracy                           0.61      1454\n",
      "   macro avg       0.57      0.56      0.55      1454\n",
      "weighted avg       0.59      0.61      0.59      1454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lg_lexicon = model.fit(train_feature_matrix,Y_train)\n",
    "pickle.dump(model, open(lg_model_path,'wb'))\n",
    "prediction = model.predict(test_feature_matrix)\n",
    "print(f\"Accuracy score is {accuracy_score(Y_test, prediction):.2f}\")\n",
    "print(classification_report(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_lexicon_model_path = 'Models/lg_lexicon_model.sav'\n",
    "pickle.dump(lg_lexicon, open(lg_lexicon_model_path,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complement Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNB = ComplementNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ComplementNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ComplementNB</label><div class=\"sk-toggleable__content\"><pre>ComplementNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ComplementNB()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNB.fit(X_train_tfidf, Y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 60.66024759284731%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.73      0.69       682\n",
      "     neutral       0.36      0.21      0.26       362\n",
      "    positive       0.64      0.75      0.69       410\n",
      "\n",
      "    accuracy                           0.61      1454\n",
      "   macro avg       0.55      0.56      0.55      1454\n",
      "weighted avg       0.58      0.61      0.58      1454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = CNB.predict(X_test_tfidf)\n",
    "acc = accuracy_score(Y_test_tfidf,predicted)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test_tfidf,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_SVC = SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip-Gram Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 51.788170563961486%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.52      0.84      0.64       682\n",
      "     neutral       0.00      0.00      0.00       362\n",
      "    positive       0.52      0.44      0.48       410\n",
      "\n",
      "    accuracy                           0.52      1454\n",
      "   macro avg       0.35      0.43      0.37      1454\n",
      "weighted avg       0.39      0.52      0.44      1454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_embedding = SVM_SVC.fit(X_train_sg,Y_train_sg)\n",
    "predicted = svc_embedding.predict(X_test_sg)\n",
    "acc = accuracy_score(Y_test_sg,predicted)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test_sg,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBOW Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 47.86795048143054%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.80      0.62       682\n",
      "     neutral       0.00      0.00      0.00       362\n",
      "    positive       0.42      0.36      0.39       410\n",
      "\n",
      "    accuracy                           0.48      1454\n",
      "   macro avg       0.31      0.39      0.33      1454\n",
      "weighted avg       0.35      0.48      0.40      1454\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "svc_embedding = SVM_SVC.fit(X_train_cb,Y_train_cb)\n",
    "predicted = svc_embedding.predict(X_test_cb)\n",
    "acc = accuracy_score(Y_test_cb,predicted)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test_cb,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 62.24209078404401%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.58      0.97      0.72       682\n",
      "     neutral       0.71      0.04      0.08       362\n",
      "    positive       0.79      0.56      0.66       410\n",
      "\n",
      "    accuracy                           0.62      1454\n",
      "   macro avg       0.69      0.52      0.49      1454\n",
      "weighted avg       0.67      0.62      0.54      1454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_tfidf = SVM_SVC.fit(X_train_tfidf,Y_train_tfidf)\n",
    "predicted = svc_tfidf.predict(X_test_tfidf)\n",
    "acc = accuracy_score(Y_test_tfidf,predicted)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test_tfidf,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 60.86657496561211%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.94      0.71       682\n",
      "     neutral       0.73      0.05      0.10       362\n",
      "    positive       0.72      0.55      0.63       410\n",
      "\n",
      "    accuracy                           0.61      1454\n",
      "   macro avg       0.68      0.51      0.48      1454\n",
      "weighted avg       0.65      0.61      0.53      1454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_count = SVM_SVC.fit(X_train_count,Y_train_count)\n",
    "predicted = svc_count.predict(X_test_count)\n",
    "acc = accuracy_score(Y_test_count,predicted)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test_count,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(in_dim, out_dim),\n",
    "    tf.keras.layers.Dense(out_dim, )\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tweets SA task.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
