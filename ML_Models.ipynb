{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKoGGi6kLGOO"
   },
   "source": [
    "# Importing Modules and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('./Scripts')\n",
    "sys.path.append('./Files')\n",
    "sys.path.append('./Datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('pip install nltk')\n",
    "os.system('pip install openpyxl')\n",
    "os.system('pip install emot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "id": "UrjWYyRaH06H",
    "outputId": "6a81f367-faab-46f2-f597-6bd3da2443c6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "import openpyxl\n",
    "import emot\n",
    "import pickle\n",
    "\n",
    "# from google.colab import files\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "nltk.download('punkt')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from Sequencer import Sequencer\n",
    "from helper_fns import write_dict\n",
    "from helper_fns import read_dict\n",
    "\n",
    "from dataCleaner import preProcess\n",
    "import ArStemmerLib as lib\n",
    "import lexicon\n",
    "from lexicon import calc_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "K8NHuxV9Jiqq"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Datasets/merged_train_datasets.csv')\n",
    "df = df.rename(columns={\"text\":\"tweet\"})\n",
    "\n",
    "try:\n",
    "    df.drop(columns=['Unnamed: 0'], inplace = True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_df = pd.read_csv('Datasets/tweets_sns2.csv')\n",
    "# keep_regex = \"[Vv]odafone|VODAFONE|فودافون|[Ee]tisalat|ETISALAT|اتصالات|[Oo]range|ORANGE|اورانج|موبينيل|إتصالات|أورانج\"\n",
    "# remove_regex = \"لون\"\n",
    "# drop_indeces = tweets_df[(tweets_df['text'].str.contains(keep_regex)==False) | (tweets_df['text'].str.contains(remove_regex)==True)].index\n",
    "# tweets_df.drop(drop_indeces, inplace=True)\n",
    "# tweets= tweets_df['text'].copy()\n",
    "# tweets2 = df['tweet'].copy()\n",
    "# tokens1 = set(nltk.word_tokenize(' '.join(tweets.to_numpy().flatten())))\n",
    "# tokens2 = set(nltk.word_tokenize(' '.join(tweets2.to_numpy().flatten())))\n",
    "# def tweet_filter(tweet: str, bucket: set[str]) -> bool:\n",
    "#     tokens = set(nltk.word_tokenize(tweet))\n",
    "#     inclusion_ratio =  len(tokens.intersection(bucket)) / len(tokens)\n",
    "#     return inclusion_ratio >= 0.5\n",
    "\n",
    "# filtered_tweets = tweets.to_numpy()[[tweet_filter(x, tokens2) for x in tweets.to_numpy()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "OAo1GEUejnmw"
   },
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7YUwwakVjsBf",
    "outputId": "617b1a14-e1e2-41d8-e427-f6d486ce65b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5819 entries, 0 to 6636\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   tweet      5819 non-null   object\n",
      " 1   sentiment  5819 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 136.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "LgTZtudCnAYh",
    "outputId": "584ef3a6-cca0-4a84-b764-4cc45ed9ce38"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>أهنئ الدكتور أحمد جمال الدين، القيادي بحزب مصر...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>البرادعي يستقوى بامريكا مرةاخرى و يرسل عصام ال...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>الوالدة لو اقولها بخاطري حشيشة تضحك بس من اقول...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#انتخبوا_العرص #انتخبوا_البرص #مرسى_رئيسى #اين...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>امير عيد هو اللي فعلا يتقال عليه ستريكر صريح #...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet sentiment\n",
       "0  أهنئ الدكتور أحمد جمال الدين، القيادي بحزب مصر...  positive\n",
       "1  البرادعي يستقوى بامريكا مرةاخرى و يرسل عصام ال...  negative\n",
       "2  الوالدة لو اقولها بخاطري حشيشة تضحك بس من اقول...   neutral\n",
       "3  #انتخبوا_العرص #انتخبوا_البرص #مرسى_رئيسى #اين...   neutral\n",
       "4  امير عيد هو اللي فعلا يتقال عليه ستريكر صريح #...  positive"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "dWmCJDvoQWET",
    "outputId": "98f72455-5352-4b51-f998-bc14483e32ac"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUhUlEQVR4nO3de5DmVX3n8fdHQBNFA4SR5ZphybjZMcYBpgAl2cWwy60SUYMEssglbI2pBSsYs1uY2gpEQ5aUt4qXkGCcABsi4oV1pFhxMkoSKREGlwADIrOAC7MII+AtJGbB7/7xOx0fsLtPz9BPX6bfr6qn+vzO73a6f93Pp8/vcp5UFZIkTed5890ASdLCZ1hIkroMC0lSl2EhSeoyLCRJXTvPdwPGYc8996zly5fPdzMkaVG59dZbv1lVyyabt0OGxfLly9m4ceN8N0OSFpUkX59qnqehJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoaW1gk2T/JF5LclWRTkt9s9Rcm2ZLktvY6YWSdtyfZnOSeJMeO1B/X6jYnOX9cbZYkTW6cT3A/Bbytqr6S5MXArUnWt3nvq6p3jy6cZCVwCvByYB/gr5K8rM3+EPDvgYeAW5Ksq6q7xth2LRL/5x2vmO8m7PAO+N075rsJWgDGFhZV9TDwcCt/N8ndwL7TrHIicFVVfR+4P8lm4LA2b3NV3QeQ5Kq2rGEhSXNkTq5ZJFkOHAx8uVWdm+T2JGuT7N7q9gUeHFntoVY3Vf2z97EmycYkG7du3Trb34IkLWljD4skuwKfBM6rqu8AlwAHAasYeh7vmY39VNWlVbW6qlYvWzbpoImSpO001lFnk+zCEBRXVtWnAKrqkZH5HwaubZNbgP1HVt+v1TFNvSRpDozzbqgAHwHurqr3jtTvPbLY64E7W3kdcEqSFyQ5EFgB3AzcAqxIcmCS5zNcBF83rnZLkn7UOHsWRwJvAu5Iclur+x3g1CSrgAIeAN4MUFWbklzNcOH6KeCcqnoaIMm5wPXATsDaqto0xnZLkp5lnHdDfRHIJLOum2adi4CLJqm/brr1JEnj5RPckqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHWNLSyS7J/kC0nuSrIpyW+2+j2SrE9yb/u6e6tPkvcn2Zzk9iSHjGzrjLb8vUnOGFebJUmTG2fP4ingbVW1EjgCOCfJSuB8YENVrQA2tGmA44EV7bUGuASGcAEuAA4HDgMumAgYSdLcGFtYVNXDVfWVVv4ucDewL3AicHlb7HLgda18InBFDW4CdkuyN3AssL6qHq+qJ4D1wHHjarck6UfNyTWLJMuBg4EvA3tV1cNt1jeAvVp5X+DBkdUeanVT1T97H2uSbEyycevWrbP7DUjSEjf2sEiyK/BJ4Lyq+s7ovKoqoGZjP1V1aVWtrqrVy5Ytm41NSpKasYZFkl0YguLKqvpUq36knV6ifX201W8B9h9Zfb9WN1W9JGmOjPNuqAAfAe6uqveOzFoHTNzRdAbw6ZH609tdUUcA326nq64Hjkmye7uwfUyrkyTNkZ3HuO0jgTcBdyS5rdX9DnAxcHWSs4GvAye3edcBJwCbgSeBswCq6vEk7wRuacu9o6oeH2O7JUnPMrawqKovApli9tGTLF/AOVNsay2wdvZaJ0naFj7BLUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqWucAwkuGof+5yvmuwk7vFvfdfp8N0HSc2DPQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6hpbWCRZm+TRJHeO1F2YZEuS29rrhJF5b0+yOck9SY4dqT+u1W1Ocv642itJmto4exaXAcdNUv++qlrVXtcBJFkJnAK8vK3zx0l2SrIT8CHgeGAlcGpbVpI0h3Ye14ar6m+SLJ/h4icCV1XV94H7k2wGDmvzNlfVfQBJrmrL3jXb7ZUkTW1sYTGNc5OcDmwE3lZVTwD7AjeNLPNQqwN48Fn1h0+20SRrgDUABxxwwGy3WdIYHPmBI+e7CTu8G99y46xsZ64vcF8CHASsAh4G3jNbG66qS6tqdVWtXrZs2WxtVpLEHPcsquqRiXKSDwPXtsktwP4ji+7X6pimXpI0R2bUs0iyYSZ1M9jO3iOTrwcm7pRaB5yS5AVJDgRWADcDtwArkhyY5PkMF8HXbet+JUnPzbQ9iyQ/BrwQ2DPJ7kDarJfww2sKU637UeCotu5DwAXAUUlWAQU8ALwZoKo2Jbma4cL1U8A5VfV02865wPXATsDaqtq0zd+lJOk56Z2GejNwHrAPcCs/DIvvAB+cbsWqOnWS6o9Ms/xFwEWT1F8HXNdppyRpjKYNi6r6I+CPkrylqj4wR22SJC0wM7rAXVUfSPJqYPnoOlV1xZjaJUlaQGYUFkn+O8Mtr7cBT7fqAgwLSVoCZnrr7GpgZVXVOBsjSVqYZvpQ3p3AvxhnQyRJC9dMexZ7AncluRn4/kRlVb12LK2SJC0oMw2LC8fZCEnSwjbTu6H+etwNkSQtXDO9G+q7DHc/ATwf2AX4+6p6ybgaJklaOGbas3jxRDlJGD5T4ohxNUqStLBs8xDlNfgfwLG9ZSVJO4aZnoZ6w8jk8xieu/jHsbRIkrTgzPRuqF8eKT/FMGLsibPeGknSgjTTaxZnjbshkqSFa6YffrRfkmuSPNpen0yy37gbJ0laGGZ6gfvPGT6hbp/2+kyrkyQtATMNi2VV9edV9VR7XQYsG2O7JEkLyEzD4rEkpyXZqb1OAx4bZ8MkSQvHTMPi14GTgW8ADwMnAWeOqU2SpAVmprfOvgM4o6qeAEiyB/BuhhCRJO3gZtqz+LmJoACoqseBg8fTJEnSQjPTsHhekt0nJlrPYqa9EknSIjfTN/z3AF9K8vE2/UbgovE0SZK00Mz0Ce4rkmwEfrFVvaGq7hpfsyRJC8mMTyW1cDAgJGkJ2uYhyiVJS49hIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktQ1trBIsrZ9qt6dI3V7JFmf5N72dfdWnyTvT7I5ye1JDhlZ54y2/L1JzhhXeyVJUxtnz+Iy4Lhn1Z0PbKiqFcCGNg1wPLCivdYAl8A/j0F1AXA4cBhwwegYVZKkuTG2sKiqvwEef1b1icDlrXw58LqR+itqcBOwW5K9gWOB9VX1eBv1dj0/GkCSpDGb62sWe1XVw638DWCvVt4XeHBkuYda3VT1PyLJmiQbk2zcunXr7LZakpa4ebvAXVUF1Cxu79KqWl1Vq5ct8+PBJWk2zXVYPNJOL9G+PtrqtwD7jyy3X6ubql6SNIfmOizWARN3NJ0BfHqk/vR2V9QRwLfb6arrgWOS7N4ubB/T6iRJc2hsn3aX5KPAUcCeSR5iuKvpYuDqJGcDXwdObotfB5wAbAaeBM6C4eNbk7wTuKUt9472ka6SpDk0trCoqlOnmHX0JMsWcM4U21kLrJ3FpkmStpFPcEuSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUNS9hkeSBJHckuS3Jxla3R5L1Se5tX3dv9Uny/iSbk9ye5JD5aLMkLWXz2bN4TVWtqqrVbfp8YENVrQA2tGmA44EV7bUGuGTOWypJS9xCOg11InB5K18OvG6k/ooa3ATslmTveWifJC1Z8xUWBXwuya1J1rS6varq4Vb+BrBXK+8LPDiy7kOt7hmSrEmyMcnGrVu3jqvdkrQk7TxP+/35qtqS5KXA+iRfHZ1ZVZWktmWDVXUpcCnA6tWrt2ldSdL05qVnUVVb2tdHgWuAw4BHJk4vta+PtsW3APuPrL5fq5MkzZE5D4skL0ry4okycAxwJ7AOOKMtdgbw6VZeB5ze7oo6Avj2yOkqSdIcmI/TUHsB1ySZ2P9fVtVnk9wCXJ3kbODrwMlt+euAE4DNwJPAWXPfZEla2uY8LKrqPuCVk9Q/Bhw9SX0B58xB0yRJU1hIt85KkhYow0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUtmrBIclySe5JsTnL+fLdHkpaSRREWSXYCPgQcD6wETk2ycn5bJUlLx6IIC+AwYHNV3VdV/wRcBZw4z22SpCUjVTXfbehKchJwXFX9xzb9JuDwqjp3ZJk1wJo2+a+Ae+a8oXNnT+Cb890IbTeP3+K1ox+7n6qqZZPN2HmuWzIuVXUpcOl8t2MuJNlYVavnux3aPh6/xWspH7vFchpqC7D/yPR+rU6SNAcWS1jcAqxIcmCS5wOnAOvmuU2StGQsitNQVfVUknOB64GdgLVVtWmemzWflsTpth2Yx2/xWrLHblFc4JYkza/FchpKkjSPDAtJUpdhscgk+Y0kp7fymUn2GZn3Zz7Zvrgk2S3JfxqZ3ifJJ+azTZpekuVJfm071/3ebLdnrnjNYhFLcgPw21W1cb7bou2TZDlwbVX97Hy3RTOT5CiGv7tfmmTezlX11DTrfq+qdh1j88bGnsUcav+RfDXJlUnuTvKJJC9McnSS/5XkjiRrk7ygLX9xkruS3J7k3a3uwiS/3Z5qXw1cmeS2JD+e5IYkq1vv410j+z0zyQdb+bQkN7d1/rSNu6UptGN2d5IPJ9mU5HPtZ31Qks8muTXJ3yb5mbb8QUluasfy9yf+k0yya5INSb7S5k0MV3MxcFA7Hu9q+7uzrXNTkpePtGXi+L6o/Z7c3H5vHPpmBrbjWF7W/s4m1p/oFVwM/EI7Zm9tf1/rknwe2DDNsV7cqsrXHL2A5UABR7bptcB/BR4EXtbqrgDOA36SYciSid7fbu3rhQz/1QDcAKwe2f4NDAGyjGEsrYn6/wn8PPCvgc8Au7T6PwZOn++fy0J+tWP2FLCqTV8NnAZsAFa0usOBz7fytcCprfwbwPdaeWfgJa28J7AZSNv+nc/a352t/Fbg91p5b+CeVv4D4LSJ3wvga8CL5vtntdBf23EsLwNOGll/4lgexdAbnKg/E3gI2GO6Yz26jcX4smcx9x6sqhtb+S+Ao4H7q+prre5y4N8A3wb+EfhIkjcAT850B1W1FbgvyRFJfhL4GeDGtq9DgVuS3Nam/+Vz/5Z2ePdX1W2tfCvDm86rgY+3n+OfMryZA7wK+Hgr/+XINgL8QZLbgb8C9gX26uz3amDiP9uTgYlrGccA57d93wD8GHDAtn1LS9a2HMttsb6qHm/l7TnWC96ieChvB/Psi0TfYuhFPHOh4UHEwxje0E8CzgV+cRv2cxXDG8xXgWuqqpIEuLyq3r49DV/Cvj9SfprhD/9bVbVqG7bxHxh6fIdW1f9L8gDDm/yUqmpLkseS/Bzwqww9FRjejH6lqnbkwTLHZVuO5VO0U/VJngc8f5rt/v1IeZuP9WJgz2LuHZDkVa38a8BGYHmSn251bwL+OsmuwE9U1XUMpyNeOcm2vgu8eIr9XMMwjPupDMEBQ3f7pCQvBUiyR5Kfeq7f0BL0HeD+JG8EyGDi+NwE/EornzKyzk8Aj7Y3j9cAEz/36Y4hwMeA/8Lwu3B7q7seeEsLf5Ic/Fy/oSVsumP5AENPHOC1wC6t3DtmUx3rRc2wmHv3AOckuRvYHXgfcBZDN/gO4AfAnzD8Ml7burJfBH5rkm1dBvzJxAXu0RlV9QRwN8OQwze3ursYrpF8rm13PdvX5dbw3+PZSf4O2MQPP1/lPOC32s/3pxlOJwJcCaxux/h0hh4fVfUYcGOSO0dvShjxCYbQuXqk7p0Mb1y3J9nUprX9pjqWHwb+bat/FT/sPdwOPJ3k75K8dZLtTXqsFztvnZ1D8TbJHV6SFwL/0E77ncJwsXvHuBtGS5rXLKTZdSjwwXaK6FvAr89vc6TZYc9CktTlNQtJUpdhIUnqMiwkSV2GhTTLkqxKcsLI9GuTnD/mfR6V5NXj3IeWNsNCmn2rgH8Oi6paV1UXj3mfRzEMWyGNhXdDSSOSvIjhAbj9GD7v/Z0MA8G9F9gV+CZwZlU9nGGI+C8Dr2EY0O/sNr0Z+HFgC/DfWnl1VZ2b5DLgH4CDgZcy3Fp7OsNDX1+uqjNbO44Bfg94AfC/gbOq6ntt6IjLgV9meDDvjQxjiN3EMHzFVuAtVfW3Y/jxaAmzZyE903HA/62qV7aHJz8LfIBh9NFDGUYKvmhk+Z2r6jCGJ7cvqKp/An4X+FhVraqqj02yj90ZwuGtwDqGp/hfDryincLak+FJ+39XVYcwDAkz+gT/N1v9JQwjED/A8NT/+9o+DQrNOh/Kk57pDuA9Sf6QYbjxJ4CfBda3oZh2Ah4eWf5T7evECKYz8Zn2hPcdwCNVdQdAG7pjOUOvZiXDMCAwDGD3pSn2+YZt+N6k7WZYSCOq6mtJDmG45vD7wOeBTVX1qilWmRjF9Glm/vc0sc4PeOYoqD9o23iaYcjrU2dxn9Jz4mkoaUSGzzR/sqr+AngXw4fhLJsYKTjJLqOfXjeF3qikPTcBR06MRNw+Ge9lY96nNC3DQnqmVwA3tw/CuYDh+sNJwB+20Udvo3/X0ReAlW004F/d1ga0D686E/hoG732SwwfYDWdzwCvb/v8hW3dp9Tj3VCSpC57FpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqev/AzdbCDzzIbbtAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = sns.countplot(x='sentiment', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_JU9GYlilEAx"
   },
   "source": [
    "# Calling methods for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "GsiNTH3TGyfF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        أهنئ الدكتور أحمد جمال الدين، القيادي بحزب مصر...\n",
       "2        البرادعي يستقوى بامريكا مرةاخرى و يرسل عصام ال...\n",
       "4        الوالدة لو اقولها بخاطري حشيشة تضحك بس من اقول...\n",
       "5        #انتخبوا_العرص #انتخبوا_البرص #مرسى_رئيسى #اين...\n",
       "6        امير عيد هو اللي فعلا يتقال عليه ستريكر صريح #...\n",
       "                               ...                        \n",
       "14283    لا ولاقى واحد بيقول قطر بتمول الوايت نايتس !!!...\n",
       "14284    اقسم بالله شركه اورانج دى عليها كرم وذوق عدى ا...\n",
       "14285    اعلان فودافون عمرو دياب واعلان اورانج  واعلان ...\n",
       "14286                   اعلان فودافون يستاهل يطلع تريند ♥️\n",
       "14287    منزلة ستوري واتساب ع حوار إنك تفتح نت من فوداف...\n",
       "Name: tweet, Length: 7502, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "oXPI8tHDk5Jl"
   },
   "outputs": [],
   "source": [
    "preProcess(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6mW7GUymhLH"
   },
   "source": [
    "# Vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "vt3_NOLVnn_N"
   },
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "2KbRcpe5CDog"
   },
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8EB9aBqUlk_I"
   },
   "source": [
    "# Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "08yU2oHFloYJ"
   },
   "outputs": [],
   "source": [
    "X_train_tfidf,X_test_tfidf,Y_train_tfidf,Y_test_tfidf = train_test_split(tfidf_vec.fit_transform(df['tweet']), df['sentiment'], test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "wBDnCyIxCcrm"
   },
   "outputs": [],
   "source": [
    "X_train_count,X_test_count,Y_train_count,Y_test_count = train_test_split(count_vec.fit_transform(df['tweet']), df['sentiment'], test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train ,X_test ,Y_train ,Y_test  = train_test_split(df['tweet'], df['sentiment'], test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10140    positive\n",
       "10364    negative\n",
       "2016     negative\n",
       "623      negative\n",
       "9780     positive\n",
       "Name: sentiment, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "Y_test_tfidf = le.fit_transform(Y_test_tfidf)\n",
    "Y_test_count = le.fit_transform(Y_test_count)\n",
    "Y_test = le.fit_transform(Y_test)\n",
    "Y_train_tfidf = le.fit_transform(Y_train_tfidf)\n",
    "Y_train_count = le.fit_transform(Y_train_count)\n",
    "Y_train = le.fit_transform(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NkPLDKRLYqJZ"
   },
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Lexicon and Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the lexicon\n",
    "tweet_train_lex = []\n",
    "for tweet in X_train:\n",
    "    tweet_train_lex.append(calc_lexicon(u\"%s\" %tweet))\n",
    "\n",
    "tweet_test_lex = []\n",
    "for tweet in X_test:\n",
    "    tweet_test_lex.append(calc_lexicon(u\"%s\" %tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "CFdraTg7YvU8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1876x2 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1378 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "tweet_lex_train_sparse = csr_matrix(tweet_train_lex)\n",
    "tweet_lex_test_sparse = csr_matrix(tweet_test_lex)\n",
    "tweet_lex_test_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "DQRPxYCmYxQg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1876x21018 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 18633 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_matrix = hstack((X_train_count, tweet_lex_train_sparse))\n",
    "test_feature_matrix = hstack((X_test_count, tweet_lex_test_sparse))\n",
    "test_feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "OvrKyk5PZqm8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 64.87206823027718%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64       620\n",
      "           1       0.37      0.22      0.27       377\n",
      "           2       0.72      0.83      0.77       879\n",
      "\n",
      "    accuracy                           0.65      1876\n",
      "   macro avg       0.57      0.57      0.56      1876\n",
      "weighted avg       0.62      0.65      0.63      1876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_lexicon = cl.fit(train_feature_matrix,Y_train)\n",
    "predicted = cl.predict(test_feature_matrix)\n",
    "acc = accuracy_score(Y_test,predicted)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_lex_model_path = 'Models/nb_lexicon_model.sav'\n",
    "pickle.dump(nb_lexicon, open(nb_lex_model_path,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNju2dCSnfow"
   },
   "source": [
    "## Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "tovTo0rFoKFr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 62.20682302771855%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.53      0.59       620\n",
      "           1       0.33      0.01      0.02       377\n",
      "           2       0.61      0.95      0.74       879\n",
      "\n",
      "    accuracy                           0.62      1876\n",
      "   macro avg       0.53      0.50      0.45      1876\n",
      "weighted avg       0.57      0.62      0.55      1876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_tfidf = cl.fit(X_train_tfidf, Y_train_tfidf)\n",
    "p = cl.predict(X_test_tfidf)\n",
    "acc = accuracy_score(Y_test_tfidf,p)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_tfidf_model_path = 'Models/nb_tfidf_model.sav'\n",
    "pickle.dump(nb_tfidf, open(nb_tfidf_model_path,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexicon + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1876x21018 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 18633 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_matrix_tf = hstack((X_train_tfidf, tweet_lex_train_sparse))\n",
    "test_feature_matrix_tf = hstack((X_test_tfidf, tweet_lex_test_sparse))\n",
    "test_feature_matrix_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 62.79317697228145%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.60      0.61       620\n",
      "           1       0.20      0.01      0.01       377\n",
      "           2       0.63      0.91      0.75       879\n",
      "\n",
      "    accuracy                           0.63      1876\n",
      "   macro avg       0.49      0.51      0.46      1876\n",
      "weighted avg       0.54      0.63      0.55      1876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_lex_tfidf = cl.fit(train_feature_matrix_tf,Y_train)\n",
    "predicted = cl.predict(test_feature_matrix_tf)\n",
    "acc = accuracy_score(Y_test,predicted)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_lex_tfidf_model_path = 'Models/nb_lex_tfidf_model.sav'\n",
    "pickle.dump(nb_lex_tfidf, open(nb_lex_tfidf_model_path,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOswlrtZJK_G"
   },
   "source": [
    "# Logistic Regression TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "4ZDYb8IzJT7S"
   },
   "outputs": [],
   "source": [
    "lg =  LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "EoBqNWdbJWB6"
   },
   "outputs": [],
   "source": [
    "# make param grid\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# create and fit the model\n",
    "model = GridSearchCV(lg, param_grid, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_model_path = 'Models/lg_tfidf_model.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "Xq49spN8JslI"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train_tfidf,Y_train_tfidf)\n",
    "pickle.dump(model, open(lg_model_path,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "QWb51vfLN3ND"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 0.67\n"
     ]
    }
   ],
   "source": [
    "# make prediction and print accuracy\n",
    "prediction = model.predict(X_test_tfidf)\n",
    "print(f\"Accuracy score is {accuracy_score(Y_test_tfidf, prediction):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "oTZWrjiQN8zg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.77      0.66       620\n",
      "           1       0.55      0.11      0.19       377\n",
      "           2       0.76      0.84      0.80       879\n",
      "\n",
      "    accuracy                           0.67      1876\n",
      "   macro avg       0.63      0.57      0.55      1876\n",
      "weighted avg       0.66      0.67      0.63      1876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Reg using Lexicon + Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 0.68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.75      0.68       620\n",
      "           1       0.51      0.14      0.22       377\n",
      "           2       0.74      0.86      0.79       879\n",
      "\n",
      "    accuracy                           0.68      1876\n",
      "   macro avg       0.62      0.58      0.56      1876\n",
      "weighted avg       0.65      0.68      0.64      1876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lg_lexicon = model.fit(train_feature_matrix,Y_train)\n",
    "pickle.dump(model, open(lg_model_path,'wb'))\n",
    "prediction = model.predict(test_feature_matrix)\n",
    "print(f\"Accuracy score is {accuracy_score(Y_test, prediction):.2f}\")\n",
    "print(classification_report(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_lexicon_model_path = 'Models/lg_lexicon_model.sav'\n",
    "pickle.dump(lg_lexicon, open(lg_lexicon_model_path,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_SVC = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = read_dict(\"Word Embeddings/dict_2_2_50.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequencer = Sequencer(df['tweet'], embeddings_dict, padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_matrix = []\n",
    "for tweet in df['tweet']:\n",
    "    tweet_vec = sequencer.padder(sequencer.text_to_vec(tweet))\n",
    "    embeddings_matrix.append(tweet_vec)\n",
    "embeddings_matrix = np.array(embeddings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008410</td>\n",
       "      <td>-0.015156</td>\n",
       "      <td>-0.015701</td>\n",
       "      <td>-0.002407</td>\n",
       "      <td>0.014450</td>\n",
       "      <td>0.012534</td>\n",
       "      <td>0.013854</td>\n",
       "      <td>0.015760</td>\n",
       "      <td>-0.017170</td>\n",
       "      <td>-0.001400</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000611</td>\n",
       "      <td>-0.015481</td>\n",
       "      <td>-0.019264</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0.013185</td>\n",
       "      <td>-0.004070</td>\n",
       "      <td>-0.022848</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>0.030873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.027249</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>-0.038116</td>\n",
       "      <td>0.023499</td>\n",
       "      <td>-0.004616</td>\n",
       "      <td>-0.049360</td>\n",
       "      <td>0.038407</td>\n",
       "      <td>0.080597</td>\n",
       "      <td>-0.059024</td>\n",
       "      <td>-0.017923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027704</td>\n",
       "      <td>-0.013298</td>\n",
       "      <td>-0.010220</td>\n",
       "      <td>-0.007417</td>\n",
       "      <td>0.062927</td>\n",
       "      <td>0.030669</td>\n",
       "      <td>-0.004728</td>\n",
       "      <td>-0.028271</td>\n",
       "      <td>0.012517</td>\n",
       "      <td>0.014055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.033095</td>\n",
       "      <td>0.019470</td>\n",
       "      <td>-0.020363</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>-0.014626</td>\n",
       "      <td>-0.105112</td>\n",
       "      <td>0.103021</td>\n",
       "      <td>0.148458</td>\n",
       "      <td>-0.119840</td>\n",
       "      <td>-0.020810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>-0.050823</td>\n",
       "      <td>-0.011283</td>\n",
       "      <td>0.006291</td>\n",
       "      <td>0.182110</td>\n",
       "      <td>0.043939</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>-0.052363</td>\n",
       "      <td>0.028714</td>\n",
       "      <td>0.061510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.117823</td>\n",
       "      <td>-0.081739</td>\n",
       "      <td>0.003649</td>\n",
       "      <td>-0.041054</td>\n",
       "      <td>-0.117537</td>\n",
       "      <td>-0.196755</td>\n",
       "      <td>0.068341</td>\n",
       "      <td>0.366526</td>\n",
       "      <td>-0.243532</td>\n",
       "      <td>-0.103234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070413</td>\n",
       "      <td>-0.035549</td>\n",
       "      <td>0.007903</td>\n",
       "      <td>0.019112</td>\n",
       "      <td>0.231619</td>\n",
       "      <td>0.024672</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>-0.092943</td>\n",
       "      <td>0.060157</td>\n",
       "      <td>0.056982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.009253</td>\n",
       "      <td>-0.001551</td>\n",
       "      <td>-0.009816</td>\n",
       "      <td>0.008598</td>\n",
       "      <td>-0.017704</td>\n",
       "      <td>-0.019205</td>\n",
       "      <td>0.005579</td>\n",
       "      <td>0.021667</td>\n",
       "      <td>0.003039</td>\n",
       "      <td>0.014501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024660</td>\n",
       "      <td>-0.003554</td>\n",
       "      <td>0.014872</td>\n",
       "      <td>0.014720</td>\n",
       "      <td>0.060099</td>\n",
       "      <td>0.027731</td>\n",
       "      <td>0.013610</td>\n",
       "      <td>-0.014391</td>\n",
       "      <td>0.017970</td>\n",
       "      <td>0.025638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.008410 -0.015156 -0.015701 -0.002407  0.014450  0.012534  0.013854   \n",
       "1 -0.027249  0.001513 -0.038116  0.023499 -0.004616 -0.049360  0.038407   \n",
       "2 -0.033095  0.019470 -0.020363  0.002425 -0.014626 -0.105112  0.103021   \n",
       "3 -0.117823 -0.081739  0.003649 -0.041054 -0.117537 -0.196755  0.068341   \n",
       "4 -0.009253 -0.001551 -0.009816  0.008598 -0.017704 -0.019205  0.005579   \n",
       "\n",
       "        7         8         9    ...       240       241       242       243  \\\n",
       "0  0.015760 -0.017170 -0.001400  ... -0.000611 -0.015481 -0.019264  0.000354   \n",
       "1  0.080597 -0.059024 -0.017923  ...  0.027704 -0.013298 -0.010220 -0.007417   \n",
       "2  0.148458 -0.119840 -0.020810  ...  0.040619 -0.050823 -0.011283  0.006291   \n",
       "3  0.366526 -0.243532 -0.103234  ...  0.070413 -0.035549  0.007903  0.019112   \n",
       "4  0.021667  0.003039  0.014501  ...  0.024660 -0.003554  0.014872  0.014720   \n",
       "\n",
       "        244       245       246       247       248       249  \n",
       "0  0.005236  0.013185 -0.004070 -0.022848 -0.000622  0.030873  \n",
       "1  0.062927  0.030669 -0.004728 -0.028271  0.012517  0.014055  \n",
       "2  0.182110  0.043939  0.000477 -0.052363  0.028714  0.061510  \n",
       "3  0.231619  0.024672  0.001036 -0.092943  0.060157  0.056982  \n",
       "4  0.060099  0.027731  0.013610 -0.014391  0.017970  0.025638  \n",
       "\n",
       "[5 rows x 250 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embedding = pd.DataFrame(embeddings_matrix)\n",
    "df_embedding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.010328</td>\n",
       "      <td>-1.056574</td>\n",
       "      <td>0.434269</td>\n",
       "      <td>-0.849692</td>\n",
       "      <td>1.393601</td>\n",
       "      <td>0.966746</td>\n",
       "      <td>-0.718053</td>\n",
       "      <td>-0.778909</td>\n",
       "      <td>0.742930</td>\n",
       "      <td>0.791072</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.640188</td>\n",
       "      <td>0.382029</td>\n",
       "      <td>-0.218101</td>\n",
       "      <td>-0.589637</td>\n",
       "      <td>-0.612417</td>\n",
       "      <td>-0.397366</td>\n",
       "      <td>0.238144</td>\n",
       "      <td>0.310932</td>\n",
       "      <td>-0.636955</td>\n",
       "      <td>-0.265218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.268283</td>\n",
       "      <td>0.273076</td>\n",
       "      <td>-0.114771</td>\n",
       "      <td>-0.006422</td>\n",
       "      <td>0.357030</td>\n",
       "      <td>0.412432</td>\n",
       "      <td>-0.464660</td>\n",
       "      <td>-0.408933</td>\n",
       "      <td>0.437811</td>\n",
       "      <td>0.389011</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175162</td>\n",
       "      <td>0.417798</td>\n",
       "      <td>0.148517</td>\n",
       "      <td>-0.856288</td>\n",
       "      <td>-0.311498</td>\n",
       "      <td>-0.092525</td>\n",
       "      <td>0.197758</td>\n",
       "      <td>0.234394</td>\n",
       "      <td>-0.345016</td>\n",
       "      <td>-0.466791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.146616</td>\n",
       "      <td>1.705424</td>\n",
       "      <td>0.320072</td>\n",
       "      <td>-0.692385</td>\n",
       "      <td>-0.187225</td>\n",
       "      <td>-0.086872</td>\n",
       "      <td>0.202192</td>\n",
       "      <td>-0.021704</td>\n",
       "      <td>-0.005546</td>\n",
       "      <td>0.318766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036939</td>\n",
       "      <td>-0.197015</td>\n",
       "      <td>0.105426</td>\n",
       "      <td>-0.385923</td>\n",
       "      <td>0.310165</td>\n",
       "      <td>0.138850</td>\n",
       "      <td>0.517012</td>\n",
       "      <td>-0.105630</td>\n",
       "      <td>0.014879</td>\n",
       "      <td>0.101997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.616509</td>\n",
       "      <td>-6.367611</td>\n",
       "      <td>0.908266</td>\n",
       "      <td>-2.107712</td>\n",
       "      <td>-5.782229</td>\n",
       "      <td>-0.907612</td>\n",
       "      <td>-0.155726</td>\n",
       "      <td>1.222654</td>\n",
       "      <td>-0.907284</td>\n",
       "      <td>-1.686823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526267</td>\n",
       "      <td>0.053228</td>\n",
       "      <td>0.883172</td>\n",
       "      <td>0.053957</td>\n",
       "      <td>0.568404</td>\n",
       "      <td>-0.197085</td>\n",
       "      <td>0.551304</td>\n",
       "      <td>-0.678354</td>\n",
       "      <td>0.713517</td>\n",
       "      <td>0.047718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.642772</td>\n",
       "      <td>0.028654</td>\n",
       "      <td>0.578435</td>\n",
       "      <td>-0.491467</td>\n",
       "      <td>-0.354530</td>\n",
       "      <td>0.682498</td>\n",
       "      <td>-0.803454</td>\n",
       "      <td>-0.745204</td>\n",
       "      <td>0.890257</td>\n",
       "      <td>1.177978</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225159</td>\n",
       "      <td>0.577440</td>\n",
       "      <td>1.165652</td>\n",
       "      <td>-0.096730</td>\n",
       "      <td>-0.326250</td>\n",
       "      <td>-0.143755</td>\n",
       "      <td>1.322511</td>\n",
       "      <td>0.430292</td>\n",
       "      <td>-0.223845</td>\n",
       "      <td>-0.327958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  1.010328 -1.056574  0.434269 -0.849692  1.393601  0.966746 -0.718053   \n",
       "1  0.268283  0.273076 -0.114771 -0.006422  0.357030  0.412432 -0.464660   \n",
       "2  0.146616  1.705424  0.320072 -0.692385 -0.187225 -0.086872  0.202192   \n",
       "3 -1.616509 -6.367611  0.908266 -2.107712 -5.782229 -0.907612 -0.155726   \n",
       "4  0.642772  0.028654  0.578435 -0.491467 -0.354530  0.682498 -0.803454   \n",
       "\n",
       "        7         8         9    ...       240       241       242       243  \\\n",
       "0 -0.778909  0.742930  0.791072  ... -0.640188  0.382029 -0.218101 -0.589637   \n",
       "1 -0.408933  0.437811  0.389011  ... -0.175162  0.417798  0.148517 -0.856288   \n",
       "2 -0.021704 -0.005546  0.318766  ...  0.036939 -0.197015  0.105426 -0.385923   \n",
       "3  1.222654 -0.907284 -1.686823  ...  0.526267  0.053228  0.883172  0.053957   \n",
       "4 -0.745204  0.890257  1.177978  ... -0.225159  0.577440  1.165652 -0.096730   \n",
       "\n",
       "        244       245       246       247       248       249  \n",
       "0 -0.612417 -0.397366  0.238144  0.310932 -0.636955 -0.265218  \n",
       "1 -0.311498 -0.092525  0.197758  0.234394 -0.345016 -0.466791  \n",
       "2  0.310165  0.138850  0.517012 -0.105630  0.014879  0.101997  \n",
       "3  0.568404 -0.197085  0.551304 -0.678354  0.713517  0.047718  \n",
       "4 -0.326250 -0.143755  1.322511  0.430292 -0.223845 -0.327958  \n",
       "\n",
       "[5 rows x 250 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(padding):\n",
    "    df_embedding[i] =( df_embedding[i] - df_embedding[i].mean() ) / df_embedding[i].std()\n",
    "    # df_embedding[str(i)] = [sequencer.padder(sequencer.text_to_vec(tweet))[i] for tweet in df['tweet']]\n",
    "    \n",
    "df_embedding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_em ,X_test_em ,Y_train_em ,Y_test_em  = train_test_split(df_embedding, df['sentiment'], test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 46.735395189003434%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.79      0.60       639\n",
      "     neutral       0.80      0.01      0.02       371\n",
      "    positive       0.44      0.38      0.41       445\n",
      "\n",
      "    accuracy                           0.47      1455\n",
      "   macro avg       0.57      0.39      0.34      1455\n",
      "weighted avg       0.55      0.47      0.39      1455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_embedding = SVM_SVC.fit(X_train_em,Y_train_em)\n",
    "predicted = svc_embedding.predict(X_test_em)\n",
    "acc = accuracy_score(Y_test_em,predicted)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test_em,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 55.53264604810997%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.51      0.95      0.66       639\n",
      "     neutral       0.72      0.05      0.09       371\n",
      "    positive       0.74      0.42      0.53       445\n",
      "\n",
      "    accuracy                           0.56      1455\n",
      "   macro avg       0.66      0.47      0.43      1455\n",
      "weighted avg       0.64      0.56      0.48      1455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_tfidf = SVM_SVC.fit(X_train_tfidf,Y_train_tfidf)\n",
    "predicted = svc_tfidf.predict(X_test_tfidf)\n",
    "acc = accuracy_score(Y_test_em,predicted)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (classification_report(Y_test_em,predicted))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tweets SA task.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
